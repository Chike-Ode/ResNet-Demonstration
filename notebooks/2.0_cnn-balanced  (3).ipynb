{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7fc152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\n",
    "import os\n",
    "import ast\n",
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import helper\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "num_classes = 12\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "patience = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "ROOT_DIR = \"/workspace/resnet/\"\n",
    "ROOT_DATA_DIR = \"/workspace/resnet/data/raw\"\n",
    "ARCHIVE_DIR = os.path.join(ROOT_DATA_DIR, \"archive.zip\")\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR)#, \"labelme-12-50k\")\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TRAIN_ANNOT_PATH = os.path.join(TRAIN_DIR, \"annotation.txt\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "TEST_ANNOT_PATH = os.path.join(TEST_DIR, \"annotation.txt\")\n",
    "CLASSES_TXT_PATH = os.path.join(DATA_DIR, \"classes.txt\")\n",
    "INTERIM_DATA_DIR = \"/workspace/resnet/data/interim/\"\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "CNN_PATH = os.path.join(MODEL_DIR, \"2.0_cnn-balanced\")\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile(ARCHIVE_DIR, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(ROOT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a023b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83419f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_balanced = pd.read_csv(os.path.join(INTERIM_DATA_DIR,\"balanced-train-40000.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(INTERIM_DATA_DIR,\"test-10000.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e6e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5, 0.5, 0.5))]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3617ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,annot_df,transform = None):\n",
    "        self.annotations = annot_df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img = Image.open(self.annotations.img_path[index])\n",
    "        y_label = torch.tensor(int(self.annotations.int_label[index]))\n",
    "        if self.transform:\n",
    "            image = transform(img)\n",
    "        else:\n",
    "            image = img\n",
    "        return (image,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3233bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fb2ca6337c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = MyDataset(train_df,transform = transform)\n",
    "test_data = MyDataset(test_df,transform = transform)\n",
    "train_data_balanced = MyDataset(train_df_balanced,transform = transform)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
    "train_loader_balanced = DataLoader(dataset = train_data_balanced, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f66bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3438\n",
       "9     3422\n",
       "7     3392\n",
       "6     3325\n",
       "11    3317\n",
       "10    3312\n",
       "8     3305\n",
       "1     3303\n",
       "2     3302\n",
       "4     3297\n",
       "5     3295\n",
       "3     3292\n",
       "Name: int_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_balanced.int_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a8bc1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_l1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_l2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_l3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_l4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_l5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_l6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=50176, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
      ")\n",
      "Epoch [1/3], Loss: 2.4907\n",
      "Epoch [1/3], Loss: 2.4792\n",
      "Epoch [1/3], Loss: 2.4756\n",
      "Epoch [1/3], Loss: 2.4930\n",
      "Epoch [1/3], Loss: 2.4782\n",
      "Epoch [1/3], Loss: 2.4862\n",
      "Epoch [1/3], Loss: 2.4819\n",
      "Epoch [1/3], Loss: 2.4841\n",
      "Epoch [1/3], Loss: 2.4785\n",
      "Epoch [1/3], Loss: 2.4783\n",
      "Epoch [1/3], Loss: 2.4909\n",
      "Epoch [1/3], Loss: 2.4876\n",
      "Epoch [1/3], Loss: 2.4891\n",
      "Epoch [1/3], Loss: 2.4812\n",
      "Epoch [1/3], Loss: 2.4777\n",
      "Epoch [1/3], Loss: 2.4914\n",
      "Epoch [1/3], Loss: 2.4799\n",
      "Epoch [1/3], Loss: 2.4796\n",
      "Epoch [1/3], Loss: 2.4797\n",
      "Epoch [1/3], Loss: 2.4813\n",
      "Epoch [1/3], Loss: 2.4946\n",
      "Epoch [1/3], Loss: 2.4851\n",
      "Epoch [1/3], Loss: 2.4888\n",
      "Epoch [1/3], Loss: 2.4897\n",
      "Epoch [1/3], Loss: 2.4873\n",
      "Epoch [1/3], Loss: 2.4777\n",
      "Epoch [1/3], Loss: 2.4792\n",
      "Epoch [1/3], Loss: 2.4834\n",
      "Epoch [1/3], Loss: 2.4797\n",
      "Epoch [1/3], Loss: 2.4851\n",
      "Epoch [1/3], Loss: 2.4838\n",
      "Epoch [1/3], Loss: 2.4762\n",
      "Epoch [1/3], Loss: 2.4809\n",
      "Epoch [1/3], Loss: 2.4808\n",
      "Epoch [1/3], Loss: 2.4783\n",
      "Epoch [1/3], Loss: 2.4817\n",
      "Epoch [1/3], Loss: 2.4777\n",
      "Epoch [1/3], Loss: 2.4768\n",
      "Epoch [1/3], Loss: 2.4792\n",
      "Epoch [1/3], Loss: 2.4758\n",
      "Epoch [1/3], Loss: 2.4762\n",
      "Epoch [1/3], Loss: 2.4759\n",
      "Epoch [1/3], Loss: 2.4761\n",
      "Epoch [1/3], Loss: 2.4815\n",
      "Epoch [1/3], Loss: 2.4713\n",
      "Epoch [1/3], Loss: 2.4718\n",
      "Epoch [1/3], Loss: 2.4753\n",
      "Epoch [1/3], Loss: 2.4894\n",
      "Epoch [1/3], Loss: 2.4757\n",
      "Epoch [1/3], Loss: 2.4742\n",
      "Epoch [1/3], Loss: 2.4707\n",
      "Epoch [1/3], Loss: 2.4736\n",
      "Epoch [1/3], Loss: 2.4788\n",
      "Epoch [1/3], Loss: 2.4712\n",
      "Epoch [1/3], Loss: 2.4758\n",
      "Epoch [1/3], Loss: 2.4751\n",
      "Epoch [1/3], Loss: 2.4775\n",
      "Epoch [1/3], Loss: 2.4652\n",
      "Epoch [1/3], Loss: 2.4721\n",
      "Epoch [1/3], Loss: 2.4748\n",
      "Epoch [1/3], Loss: 2.4724\n",
      "Epoch [1/3], Loss: 2.4708\n",
      "Epoch [1/3], Loss: 2.4712\n",
      "Epoch [1/3], Loss: 2.4725\n",
      "Epoch [1/3], Loss: 2.4711\n",
      "Epoch [1/3], Loss: 2.4781\n",
      "Epoch [1/3], Loss: 2.4684\n",
      "Epoch [1/3], Loss: 2.4710\n",
      "Epoch [1/3], Loss: 2.4655\n",
      "Epoch [1/3], Loss: 2.4653\n",
      "Epoch [1/3], Loss: 2.4541\n",
      "Epoch [1/3], Loss: 2.4734\n",
      "Epoch [1/3], Loss: 2.4583\n",
      "Epoch [1/3], Loss: 2.4667\n",
      "Epoch [1/3], Loss: 2.4832\n",
      "Epoch [1/3], Loss: 2.4562\n",
      "Epoch [1/3], Loss: 2.4568\n",
      "Epoch [1/3], Loss: 2.4734\n",
      "Epoch [1/3], Loss: 2.4625\n",
      "Epoch [1/3], Loss: 2.4527\n",
      "Epoch [1/3], Loss: 2.4602\n",
      "Epoch [1/3], Loss: 2.4585\n",
      "Epoch [1/3], Loss: 2.4724\n",
      "Epoch [1/3], Loss: 2.4541\n",
      "Epoch [1/3], Loss: 2.4605\n",
      "Epoch [1/3], Loss: 2.4518\n",
      "Epoch [1/3], Loss: 2.4574\n",
      "Epoch [1/3], Loss: 2.4506\n",
      "Epoch [1/3], Loss: 2.4535\n",
      "Epoch [1/3], Loss: 2.4298\n",
      "Epoch [1/3], Loss: 2.4501\n",
      "Epoch [1/3], Loss: 2.4600\n",
      "Epoch [1/3], Loss: 2.4593\n",
      "Epoch [1/3], Loss: 2.4460\n",
      "Epoch [1/3], Loss: 2.4380\n",
      "Epoch [1/3], Loss: 2.4456\n",
      "Epoch [1/3], Loss: 2.4392\n",
      "Epoch [1/3], Loss: 2.4874\n",
      "Epoch [1/3], Loss: 2.4298\n",
      "Epoch [1/3], Loss: 2.4469\n",
      "Epoch [1/3], Loss: 2.4544\n",
      "Epoch [1/3], Loss: 2.4394\n",
      "Epoch [1/3], Loss: 2.4425\n",
      "Epoch [1/3], Loss: 2.4074\n",
      "Epoch [1/3], Loss: 2.4029\n",
      "Epoch [1/3], Loss: 2.4555\n",
      "Epoch [1/3], Loss: 2.4044\n",
      "Epoch [1/3], Loss: 2.4222\n",
      "Epoch [1/3], Loss: 2.4284\n",
      "Epoch [1/3], Loss: 2.4354\n",
      "Epoch [1/3], Loss: 2.4292\n",
      "Epoch [1/3], Loss: 2.4148\n",
      "Epoch [1/3], Loss: 2.4072\n",
      "Epoch [1/3], Loss: 2.3530\n",
      "Epoch [1/3], Loss: 2.4332\n",
      "Epoch [1/3], Loss: 2.4213\n",
      "Epoch [1/3], Loss: 2.4355\n",
      "Epoch [1/3], Loss: 2.4087\n",
      "Epoch [1/3], Loss: 2.3942\n",
      "Epoch [1/3], Loss: 2.4143\n",
      "Epoch [1/3], Loss: 2.3971\n",
      "Epoch [1/3], Loss: 2.3530\n",
      "Epoch [1/3], Loss: 2.4022\n",
      "Epoch [1/3], Loss: 2.3432\n",
      "Epoch [1/3], Loss: 2.3486\n",
      "Epoch [1/3], Loss: 2.3579\n",
      "Epoch [1/3], Loss: 2.3907\n",
      "Epoch [1/3], Loss: 2.3640\n",
      "Epoch [1/3], Loss: 2.3631\n",
      "Epoch [1/3], Loss: 2.3526\n",
      "Epoch [1/3], Loss: 2.3748\n",
      "Epoch [1/3], Loss: 2.4149\n",
      "Epoch [1/3], Loss: 2.2781\n",
      "Epoch [1/3], Loss: 2.2830\n",
      "Epoch [1/3], Loss: 2.2962\n",
      "Epoch [1/3], Loss: 2.2930\n",
      "Epoch [1/3], Loss: 2.3356\n",
      "Epoch [1/3], Loss: 2.3811\n",
      "Epoch [1/3], Loss: 2.3036\n",
      "Epoch [1/3], Loss: 2.2512\n",
      "Epoch [1/3], Loss: 2.2454\n",
      "Epoch [1/3], Loss: 2.2889\n",
      "Epoch [1/3], Loss: 2.3141\n",
      "Epoch [1/3], Loss: 2.3220\n",
      "Epoch [1/3], Loss: 2.3829\n",
      "Epoch [1/3], Loss: 2.1779\n",
      "Epoch [1/3], Loss: 2.3417\n",
      "Epoch [1/3], Loss: 2.2831\n",
      "Epoch [1/3], Loss: 2.2610\n",
      "Epoch [1/3], Loss: 2.1764\n",
      "Epoch [1/3], Loss: 2.2695\n",
      "Epoch [1/3], Loss: 2.2560\n",
      "Epoch [1/3], Loss: 2.2110\n",
      "Epoch [1/3], Loss: 2.2027\n",
      "Epoch [1/3], Loss: 2.1238\n",
      "Epoch [1/3], Loss: 2.3220\n",
      "Epoch [1/3], Loss: 2.1269\n",
      "Epoch [1/3], Loss: 2.1548\n",
      "Epoch [1/3], Loss: 2.1347\n",
      "Epoch [1/3], Loss: 2.0862\n",
      "Epoch [1/3], Loss: 2.0258\n",
      "Epoch [1/3], Loss: 2.0799\n",
      "Epoch [1/3], Loss: 2.1138\n",
      "Epoch [1/3], Loss: 2.1322\n",
      "Epoch [1/3], Loss: 2.1839\n",
      "Epoch [1/3], Loss: 2.1417\n",
      "Epoch [1/3], Loss: 2.0207\n",
      "Epoch [1/3], Loss: 2.0430\n",
      "Epoch [1/3], Loss: 2.1326\n",
      "Epoch [1/3], Loss: 2.0840\n",
      "Epoch [1/3], Loss: 2.2713\n",
      "Epoch [1/3], Loss: 2.0660\n",
      "Epoch [1/3], Loss: 2.2805\n",
      "Epoch [1/3], Loss: 2.0372\n",
      "Epoch [1/3], Loss: 2.0244\n",
      "Epoch [1/3], Loss: 2.2753\n",
      "Epoch [1/3], Loss: 2.1137\n",
      "Epoch [1/3], Loss: 2.3059\n",
      "Epoch [1/3], Loss: 2.0288\n",
      "Epoch [1/3], Loss: 2.1689\n",
      "Epoch [1/3], Loss: 2.0851\n",
      "Epoch [1/3], Loss: 1.9471\n",
      "Epoch [1/3], Loss: 2.1036\n",
      "Epoch [1/3], Loss: 1.9857\n",
      "Epoch [1/3], Loss: 2.0350\n",
      "Epoch [1/3], Loss: 2.2015\n",
      "Epoch [1/3], Loss: 2.1209\n",
      "Epoch [1/3], Loss: 1.9346\n",
      "Epoch [1/3], Loss: 2.0844\n",
      "Epoch [1/3], Loss: 2.0738\n",
      "Epoch [1/3], Loss: 2.1503\n",
      "Epoch [1/3], Loss: 1.8269\n",
      "Epoch [1/3], Loss: 2.0230\n",
      "Epoch [1/3], Loss: 1.8756\n",
      "Epoch [1/3], Loss: 2.1155\n",
      "Epoch [1/3], Loss: 2.2857\n",
      "Epoch [1/3], Loss: 2.0569\n",
      "Epoch [1/3], Loss: 1.8584\n",
      "Epoch [1/3], Loss: 2.0599\n",
      "Epoch [1/3], Loss: 2.1095\n",
      "Epoch [1/3], Loss: 2.1421\n",
      "Epoch [1/3], Loss: 2.1796\n",
      "Epoch [1/3], Loss: 2.2499\n",
      "Epoch [1/3], Loss: 2.2265\n",
      "Epoch [1/3], Loss: 1.8498\n",
      "Epoch [1/3], Loss: 1.9649\n",
      "Epoch [1/3], Loss: 1.9974\n",
      "Epoch [1/3], Loss: 2.0633\n",
      "Epoch [1/3], Loss: 2.0096\n",
      "Epoch [1/3], Loss: 2.0427\n",
      "Epoch [1/3], Loss: 2.0361\n",
      "Epoch [1/3], Loss: 2.1643\n",
      "Epoch [1/3], Loss: 1.9391\n",
      "Epoch [1/3], Loss: 1.7981\n",
      "Epoch [1/3], Loss: 2.2183\n",
      "Epoch [1/3], Loss: 1.8332\n",
      "Epoch [1/3], Loss: 1.9987\n",
      "Epoch [1/3], Loss: 2.0248\n",
      "Epoch [1/3], Loss: 2.1272\n",
      "Epoch [1/3], Loss: 2.0469\n",
      "Epoch [1/3], Loss: 2.2706\n",
      "Epoch [1/3], Loss: 2.0968\n",
      "Epoch [1/3], Loss: 2.1128\n",
      "Epoch [1/3], Loss: 1.9356\n",
      "Epoch [1/3], Loss: 1.8614\n",
      "Epoch [1/3], Loss: 2.0865\n",
      "Epoch [1/3], Loss: 1.9276\n",
      "Epoch [1/3], Loss: 1.7732\n",
      "Epoch [1/3], Loss: 2.0512\n",
      "Epoch [1/3], Loss: 2.2501\n",
      "Epoch [1/3], Loss: 2.0194\n",
      "Epoch [1/3], Loss: 2.0112\n",
      "Epoch [1/3], Loss: 2.0238\n",
      "Epoch [1/3], Loss: 1.9008\n",
      "Epoch [1/3], Loss: 1.9921\n",
      "Epoch [1/3], Loss: 2.0763\n",
      "Epoch [1/3], Loss: 1.8603\n",
      "Epoch [1/3], Loss: 1.9218\n",
      "Epoch [1/3], Loss: 1.8666\n",
      "Epoch [1/3], Loss: 2.1671\n",
      "Epoch [1/3], Loss: 1.9658\n",
      "Epoch [1/3], Loss: 2.0351\n",
      "Epoch [1/3], Loss: 2.1068\n",
      "Epoch [1/3], Loss: 2.0348\n",
      "Epoch [1/3], Loss: 1.7308\n",
      "Epoch [1/3], Loss: 2.0989\n",
      "Epoch [1/3], Loss: 1.7996\n",
      "Epoch [1/3], Loss: 2.0594\n",
      "Epoch [1/3], Loss: 1.8426\n",
      "Epoch [1/3], Loss: 2.1513\n",
      "Epoch [1/3], Loss: 2.0604\n",
      "Epoch [1/3], Loss: 1.7477\n",
      "Epoch [1/3], Loss: 2.0259\n",
      "Epoch [1/3], Loss: 1.9965\n",
      "Epoch [1/3], Loss: 2.0745\n",
      "Epoch [1/3], Loss: 2.0235\n",
      "Epoch [1/3], Loss: 1.8990\n",
      "Epoch [1/3], Loss: 1.8509\n",
      "Epoch [1/3], Loss: 1.8908\n",
      "Epoch [1/3], Loss: 2.0347\n",
      "Epoch [1/3], Loss: 1.7340\n",
      "Epoch [1/3], Loss: 2.0184\n",
      "Epoch [1/3], Loss: 1.9603\n",
      "Epoch [1/3], Loss: 2.3442\n",
      "Epoch [1/3], Loss: 1.8201\n",
      "Epoch [1/3], Loss: 2.0992\n",
      "Epoch [1/3], Loss: 1.6594\n",
      "Epoch [1/3], Loss: 2.1137\n",
      "Epoch [1/3], Loss: 1.9446\n",
      "Epoch [1/3], Loss: 1.9509\n",
      "Epoch [1/3], Loss: 2.0568\n",
      "Epoch [1/3], Loss: 2.0978\n",
      "Epoch [1/3], Loss: 1.9378\n",
      "Epoch [1/3], Loss: 1.9178\n",
      "Epoch [1/3], Loss: 1.8763\n",
      "Epoch [1/3], Loss: 1.9074\n",
      "Epoch [1/3], Loss: 1.8894\n",
      "Epoch [1/3], Loss: 1.8435\n",
      "Epoch [1/3], Loss: 1.9338\n",
      "Epoch [1/3], Loss: 1.9162\n",
      "Epoch [1/3], Loss: 1.8330\n",
      "Epoch [1/3], Loss: 1.7103\n",
      "Epoch [1/3], Loss: 1.9351\n",
      "Epoch [1/3], Loss: 1.8474\n",
      "Epoch [1/3], Loss: 1.8397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 2.2488\n",
      "Epoch [1/3], Loss: 1.7551\n",
      "Epoch [1/3], Loss: 1.7578\n",
      "Epoch [1/3], Loss: 2.0122\n",
      "Epoch [1/3], Loss: 2.0154\n",
      "Epoch [1/3], Loss: 2.1456\n",
      "Epoch [1/3], Loss: 2.1931\n",
      "Epoch [1/3], Loss: 1.8949\n",
      "Epoch [1/3], Loss: 1.8586\n",
      "Epoch [1/3], Loss: 2.1078\n",
      "Epoch [1/3], Loss: 1.7528\n",
      "Epoch [1/3], Loss: 1.8096\n",
      "Epoch [1/3], Loss: 1.7895\n",
      "Epoch [1/3], Loss: 1.9979\n",
      "Epoch [1/3], Loss: 1.9388\n",
      "Epoch [1/3], Loss: 1.8985\n",
      "Epoch [1/3], Loss: 1.8541\n",
      "Epoch [1/3], Loss: 1.7786\n",
      "Epoch [1/3], Loss: 2.0900\n",
      "Epoch [1/3], Loss: 1.8190\n",
      "Epoch [1/3], Loss: 1.7298\n",
      "Epoch [1/3], Loss: 1.6675\n",
      "Epoch [1/3], Loss: 1.7577\n",
      "Epoch [1/3], Loss: 1.9448\n",
      "Epoch [1/3], Loss: 1.7860\n",
      "Epoch [1/3], Loss: 1.9789\n",
      "Epoch [1/3], Loss: 2.0221\n",
      "Epoch [1/3], Loss: 1.6371\n",
      "Epoch [1/3], Loss: 1.9222\n",
      "Epoch [1/3], Loss: 1.9297\n",
      "Epoch [1/3], Loss: 1.9478\n",
      "Epoch [1/3], Loss: 2.0459\n",
      "Epoch [1/3], Loss: 1.9681\n",
      "Epoch [1/3], Loss: 1.7442\n",
      "Epoch [1/3], Loss: 1.8064\n",
      "Epoch [1/3], Loss: 1.8856\n",
      "Epoch [1/3], Loss: 1.8590\n",
      "Epoch [1/3], Loss: 1.8365\n",
      "Epoch [1/3], Loss: 1.7398\n",
      "Epoch [1/3], Loss: 1.6720\n",
      "Epoch [1/3], Loss: 1.7520\n",
      "Epoch [1/3], Loss: 1.8851\n",
      "Epoch [1/3], Loss: 1.7957\n",
      "Epoch [1/3], Loss: 1.9459\n",
      "Epoch [1/3], Loss: 1.7966\n",
      "Epoch [1/3], Loss: 1.7245\n",
      "Epoch [1/3], Loss: 1.6148\n",
      "Epoch [1/3], Loss: 1.6877\n",
      "Epoch [1/3], Loss: 1.6307\n",
      "Epoch [1/3], Loss: 1.7444\n",
      "Epoch [1/3], Loss: 1.5944\n",
      "Epoch [1/3], Loss: 1.8354\n",
      "Epoch [1/3], Loss: 1.7003\n",
      "Epoch [1/3], Loss: 1.8233\n",
      "Epoch [1/3], Loss: 1.8651\n",
      "Epoch [1/3], Loss: 1.7513\n",
      "Epoch [1/3], Loss: 2.0429\n",
      "Epoch [1/3], Loss: 1.8387\n",
      "Epoch [1/3], Loss: 1.6123\n",
      "Epoch [1/3], Loss: 1.8739\n",
      "Epoch [1/3], Loss: 1.6652\n",
      "Epoch [1/3], Loss: 1.8211\n",
      "Epoch [1/3], Loss: 1.6677\n",
      "Epoch [1/3], Loss: 1.8211\n",
      "Epoch [1/3], Loss: 1.8480\n",
      "Epoch [1/3], Loss: 1.8119\n",
      "Epoch [1/3], Loss: 1.5670\n",
      "Epoch [1/3], Loss: 1.6626\n",
      "Epoch [1/3], Loss: 2.0012\n",
      "Epoch [1/3], Loss: 1.5772\n",
      "Epoch [1/3], Loss: 1.7082\n",
      "Epoch [1/3], Loss: 1.8891\n",
      "Epoch [1/3], Loss: 1.8732\n",
      "Epoch [1/3], Loss: 1.7107\n",
      "Epoch [1/3], Loss: 1.5445\n",
      "Epoch [1/3], Loss: 1.6370\n",
      "Epoch [1/3], Loss: 1.6829\n",
      "Epoch [1/3], Loss: 1.7586\n",
      "Epoch [1/3], Loss: 1.8359\n",
      "Epoch [1/3], Loss: 1.8502\n",
      "Epoch [1/3], Loss: 1.7682\n",
      "Epoch [1/3], Loss: 1.5978\n",
      "Epoch [1/3], Loss: 1.5304\n",
      "Epoch [1/3], Loss: 1.7932\n",
      "Epoch [1/3], Loss: 1.7899\n",
      "Epoch [1/3], Loss: 1.5615\n",
      "Epoch [1/3], Loss: 1.9387\n",
      "Epoch [1/3], Loss: 1.8654\n",
      "Epoch [1/3], Loss: 1.7766\n",
      "Epoch [1/3], Loss: 1.7923\n",
      "Epoch [1/3], Loss: 1.8266\n",
      "Epoch [1/3], Loss: 1.8207\n",
      "Epoch [1/3], Loss: 1.8096\n",
      "Epoch [1/3], Loss: 1.7080\n",
      "Epoch [1/3], Loss: 1.6473\n",
      "Epoch [1/3], Loss: 1.8157\n",
      "Epoch [1/3], Loss: 1.4976\n",
      "Epoch [1/3], Loss: 1.8147\n",
      "Epoch [1/3], Loss: 1.9938\n",
      "Epoch [1/3], Loss: 1.9788\n",
      "Epoch [1/3], Loss: 1.7554\n",
      "Epoch [1/3], Loss: 1.8274\n",
      "Epoch [1/3], Loss: 1.6522\n",
      "Epoch [1/3], Loss: 1.7010\n",
      "Epoch [1/3], Loss: 1.5755\n",
      "Epoch [1/3], Loss: 1.9259\n",
      "Epoch [1/3], Loss: 1.6999\n",
      "Epoch [1/3], Loss: 1.8011\n",
      "Epoch [1/3], Loss: 1.7971\n",
      "Epoch [1/3], Loss: 1.7620\n",
      "Epoch [1/3], Loss: 1.7766\n",
      "Epoch [1/3], Loss: 1.5494\n",
      "Epoch [1/3], Loss: 1.5702\n",
      "Epoch [1/3], Loss: 1.6126\n",
      "Epoch [1/3], Loss: 1.9960\n",
      "Epoch [1/3], Loss: 1.6681\n",
      "Epoch [1/3], Loss: 1.4814\n",
      "Epoch [1/3], Loss: 1.5832\n",
      "Epoch [1/3], Loss: 1.8113\n",
      "Epoch [1/3], Loss: 1.5287\n",
      "Epoch [1/3], Loss: 1.5347\n",
      "Epoch [1/3], Loss: 2.0015\n",
      "Epoch [1/3], Loss: 1.7355\n",
      "Epoch [1/3], Loss: 1.5517\n",
      "Epoch [1/3], Loss: 1.6762\n",
      "Epoch [1/3], Loss: 1.5729\n",
      "Epoch [1/3], Loss: 1.8318\n",
      "Epoch [1/3], Loss: 1.6615\n",
      "Epoch [1/3], Loss: 1.6739\n",
      "Epoch [1/3], Loss: 1.7369\n",
      "Epoch [1/3], Loss: 1.8980\n",
      "Epoch [1/3], Loss: 1.8447\n",
      "Epoch [1/3], Loss: 1.6065\n",
      "Epoch [1/3], Loss: 1.7866\n",
      "Epoch [1/3], Loss: 1.7442\n",
      "Epoch [1/3], Loss: 1.6747\n",
      "Epoch [1/3], Loss: 1.7302\n",
      "Epoch [1/3], Loss: 1.7245\n",
      "Epoch [1/3], Loss: 1.5020\n",
      "Epoch [1/3], Loss: 1.3234\n",
      "Epoch [1/3], Loss: 1.7404\n",
      "Epoch [1/3], Loss: 1.5898\n",
      "Epoch [1/3], Loss: 1.4574\n",
      "Epoch [1/3], Loss: 1.6735\n",
      "Epoch [1/3], Loss: 1.8672\n",
      "Epoch [1/3], Loss: 1.7533\n",
      "Epoch [1/3], Loss: 1.7609\n",
      "Epoch [1/3], Loss: 1.5449\n",
      "Epoch [1/3], Loss: 1.6032\n",
      "Epoch [1/3], Loss: 1.4952\n",
      "Epoch [1/3], Loss: 1.7664\n",
      "Epoch [1/3], Loss: 1.6698\n",
      "Epoch [1/3], Loss: 1.6465\n",
      "Epoch [1/3], Loss: 1.3191\n",
      "Epoch [1/3], Loss: 1.4201\n",
      "Epoch [1/3], Loss: 1.6526\n",
      "Epoch [1/3], Loss: 1.6308\n",
      "Epoch [1/3], Loss: 1.3634\n",
      "Epoch [1/3], Loss: 1.6550\n",
      "Epoch [1/3], Loss: 1.7052\n",
      "Epoch [1/3], Loss: 1.7602\n",
      "Epoch [1/3], Loss: 1.4824\n",
      "Epoch [1/3], Loss: 1.7178\n",
      "Epoch [1/3], Loss: 1.4118\n",
      "Epoch [1/3], Loss: 1.5544\n",
      "Epoch [1/3], Loss: 1.5169\n",
      "Epoch [1/3], Loss: 1.4943\n",
      "Epoch [1/3], Loss: 1.8299\n",
      "Epoch [1/3], Loss: 1.5769\n",
      "Epoch [1/3], Loss: 1.5439\n",
      "Epoch [1/3], Loss: 1.3945\n",
      "Epoch [1/3], Loss: 1.4523\n",
      "Epoch [1/3], Loss: 1.8115\n",
      "Epoch [1/3], Loss: 1.5601\n",
      "Epoch [1/3], Loss: 1.2899\n",
      "Epoch [1/3], Loss: 1.6070\n",
      "Epoch [1/3], Loss: 1.4449\n",
      "Epoch [1/3], Loss: 1.5416\n",
      "Epoch [1/3], Loss: 1.8341\n",
      "Epoch [1/3], Loss: 1.6506\n",
      "Epoch [1/3], Loss: 1.3694\n",
      "Epoch [1/3], Loss: 1.6676\n",
      "Epoch [1/3], Loss: 1.5408\n",
      "Epoch [1/3], Loss: 1.5971\n",
      "Epoch [1/3], Loss: 1.4471\n",
      "Epoch [1/3], Loss: 1.4869\n",
      "Epoch [1/3], Loss: 1.6810\n",
      "Epoch [1/3], Loss: 1.3270\n",
      "Epoch [1/3], Loss: 1.5117\n",
      "Epoch [1/3], Loss: 1.3446\n",
      "Epoch [1/3], Loss: 1.4509\n",
      "Epoch [1/3], Loss: 1.4606\n",
      "Epoch [1/3], Loss: 1.5377\n",
      "Epoch [1/3], Loss: 1.4912\n",
      "Epoch [1/3], Loss: 1.3954\n",
      "Epoch [1/3], Loss: 1.3910\n",
      "Epoch [1/3], Loss: 1.5032\n",
      "Epoch [1/3], Loss: 1.3510\n",
      "Epoch [1/3], Loss: 1.4144\n",
      "Epoch [1/3], Loss: 1.7505\n",
      "Epoch [1/3], Loss: 1.6168\n",
      "Epoch [1/3], Loss: 1.7645\n",
      "Epoch [1/3], Loss: 1.7060\n",
      "Epoch [1/3], Loss: 1.5678\n",
      "Epoch [1/3], Loss: 1.3227\n",
      "Epoch [1/3], Loss: 1.5053\n",
      "Epoch [1/3], Loss: 1.5037\n",
      "Epoch [1/3], Loss: 1.4421\n",
      "Epoch [1/3], Loss: 1.5268\n",
      "Epoch [1/3], Loss: 1.3503\n",
      "Epoch [1/3], Loss: 1.6825\n",
      "Epoch [1/3], Loss: 1.5018\n",
      "Epoch [1/3], Loss: 1.4067\n",
      "Epoch [1/3], Loss: 1.4146\n",
      "Epoch [1/3], Loss: 1.6649\n",
      "Epoch [1/3], Loss: 1.4738\n",
      "Epoch [1/3], Loss: 1.5999\n",
      "Epoch [1/3], Loss: 1.4193\n",
      "Epoch [1/3], Loss: 1.7048\n",
      "Epoch [1/3], Loss: 1.4442\n",
      "Epoch [1/3], Loss: 1.6066\n",
      "Epoch [1/3], Loss: 1.2963\n",
      "Epoch [1/3], Loss: 1.5717\n",
      "Epoch [1/3], Loss: 1.2915\n",
      "Epoch [1/3], Loss: 1.7991\n",
      "Epoch [1/3], Loss: 1.5587\n",
      "Epoch [1/3], Loss: 1.6168\n",
      "Epoch [1/3], Loss: 1.4021\n",
      "Epoch [1/3], Loss: 1.5010\n",
      "Epoch [1/3], Loss: 1.7019\n",
      "Epoch [1/3], Loss: 1.9455\n",
      "Epoch [1/3], Loss: 1.3041\n",
      "Epoch [1/3], Loss: 1.3049\n",
      "Epoch [1/3], Loss: 1.5277\n",
      "Epoch [1/3], Loss: 1.7382\n",
      "Epoch [1/3], Loss: 1.7704\n",
      "Epoch [1/3], Loss: 1.4513\n",
      "Epoch [1/3], Loss: 1.1515\n",
      "Epoch [1/3], Loss: 1.5726\n",
      "Epoch [1/3], Loss: 1.5875\n",
      "Epoch [1/3], Loss: 1.4989\n",
      "Epoch [1/3], Loss: 1.5002\n",
      "Epoch [1/3], Loss: 1.5351\n",
      "Epoch [1/3], Loss: 1.5171\n",
      "Epoch [1/3], Loss: 1.3275\n",
      "Epoch [1/3], Loss: 1.6840\n",
      "Epoch [1/3], Loss: 1.4900\n",
      "Epoch [1/3], Loss: 1.5400\n",
      "Epoch [1/3], Loss: 1.3043\n",
      "Epoch [1/3], Loss: 1.4987\n",
      "Epoch [1/3], Loss: 1.3685\n",
      "Epoch [1/3], Loss: 1.3032\n",
      "Epoch [1/3], Loss: 1.4592\n",
      "Epoch [1/3], Loss: 1.3879\n",
      "Epoch [1/3], Loss: 1.5376\n",
      "Epoch [1/3], Loss: 1.3661\n",
      "Epoch [1/3], Loss: 1.5720\n",
      "Epoch [1/3], Loss: 1.5604\n",
      "Epoch [1/3], Loss: 1.0093\n",
      "Epoch [1/3], Loss: 1.3851\n",
      "Epoch [1/3], Loss: 1.4008\n",
      "Epoch [1/3], Loss: 1.7304\n",
      "Epoch [1/3], Loss: 1.4950\n",
      "Epoch [1/3], Loss: 1.5785\n",
      "Epoch [1/3], Loss: 1.2255\n",
      "Epoch [1/3], Loss: 1.4723\n",
      "Epoch [1/3], Loss: 1.4815\n",
      "Epoch [1/3], Loss: 1.4981\n",
      "Epoch [1/3], Loss: 1.5448\n",
      "Epoch [1/3], Loss: 1.3462\n",
      "Epoch [1/3], Loss: 1.7092\n",
      "Epoch [1/3], Loss: 1.6667\n",
      "Epoch [1/3], Loss: 1.4487\n",
      "Epoch [1/3], Loss: 1.5363\n",
      "Epoch [1/3], Loss: 1.6534\n",
      "Epoch [1/3], Loss: 1.7311\n",
      "Epoch [1/3], Loss: 1.4561\n",
      "Epoch [1/3], Loss: 1.2751\n",
      "Epoch [1/3], Loss: 1.4979\n",
      "Epoch [1/3], Loss: 1.4503\n",
      "Epoch [1/3], Loss: 1.5540\n",
      "Epoch [1/3], Loss: 1.6038\n",
      "Epoch [1/3], Loss: 1.5599\n",
      "Epoch [1/3], Loss: 1.7327\n",
      "Epoch [1/3], Loss: 1.6032\n",
      "Epoch [1/3], Loss: 1.4817\n",
      "Epoch [1/3], Loss: 1.4492\n",
      "Epoch [1/3], Loss: 1.1460\n",
      "Epoch [1/3], Loss: 1.5816\n",
      "Epoch [1/3], Loss: 1.3242\n",
      "Epoch [1/3], Loss: 1.5178\n",
      "Epoch [1/3], Loss: 1.4798\n",
      "Epoch [1/3], Loss: 1.6542\n",
      "Epoch [1/3], Loss: 1.5212\n",
      "Epoch [1/3], Loss: 1.5031\n",
      "Epoch [1/3], Loss: 1.3940\n",
      "Epoch [1/3], Loss: 1.5705\n",
      "Epoch [1/3], Loss: 1.2919\n",
      "Epoch [1/3], Loss: 1.5425\n",
      "Epoch [1/3], Loss: 1.3336\n",
      "Epoch [1/3], Loss: 1.1294\n",
      "Epoch [1/3], Loss: 1.2623\n",
      "Epoch [1/3], Loss: 1.4367\n",
      "Epoch [1/3], Loss: 1.2203\n",
      "Epoch [1/3], Loss: 1.5363\n",
      "Epoch [1/3], Loss: 1.4096\n",
      "Epoch [1/3], Loss: 1.1821\n",
      "Epoch [1/3], Loss: 1.4934\n",
      "Epoch [1/3], Loss: 1.4307\n",
      "Epoch [1/3], Loss: 1.3669\n",
      "Epoch [1/3], Loss: 1.2653\n",
      "Epoch [1/3], Loss: 1.5618\n",
      "Epoch [1/3], Loss: 1.3943\n",
      "Epoch [1/3], Loss: 1.3800\n",
      "Epoch [1/3], Loss: 1.6521\n",
      "Epoch [1/3], Loss: 1.7883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.2574\n",
      "Epoch [1/3], Loss: 1.4609\n",
      "Epoch [1/3], Loss: 1.5993\n",
      "Epoch [1/3], Loss: 1.7880\n",
      "Epoch [1/3], Loss: 1.4054\n",
      "Epoch [1/3], Loss: 1.3235\n",
      "Epoch [1/3], Loss: 1.3823\n",
      "Epoch [1/3], Loss: 1.1258\n",
      "Epoch [1/3], Loss: 1.3052\n",
      "Epoch [1/3], Loss: 1.3033\n",
      "Epoch [1/3], Loss: 1.4108\n",
      "Epoch [1/3], Loss: 1.3003\n",
      "Epoch [1/3], Loss: 1.3552\n",
      "Epoch [1/3], Loss: 1.2758\n",
      "Epoch [1/3], Loss: 1.4978\n",
      "Epoch [1/3], Loss: 1.6638\n",
      "Epoch [1/3], Loss: 1.4251\n",
      "Epoch [1/3], Loss: 1.3808\n",
      "Epoch [1/3], Loss: 1.3840\n",
      "Epoch [1/3], Loss: 1.4109\n",
      "Epoch [1/3], Loss: 1.3898\n",
      "Epoch [1/3], Loss: 1.4427\n",
      "Epoch [1/3], Loss: 1.7481\n",
      "Epoch [1/3], Loss: 1.1206\n",
      "Epoch [1/3], Loss: 1.1206\n",
      "Epoch [2/3], Loss: 1.3294\n",
      "Epoch [2/3], Loss: 1.3862\n",
      "Epoch [2/3], Loss: 1.2846\n",
      "Epoch [2/3], Loss: 1.5280\n",
      "Epoch [2/3], Loss: 0.9812\n",
      "Epoch [2/3], Loss: 1.2763\n",
      "Epoch [2/3], Loss: 1.3720\n",
      "Epoch [2/3], Loss: 1.3451\n",
      "Epoch [2/3], Loss: 1.8149\n",
      "Epoch [2/3], Loss: 1.4851\n",
      "Epoch [2/3], Loss: 1.3395\n",
      "Epoch [2/3], Loss: 1.1345\n",
      "Epoch [2/3], Loss: 1.3150\n",
      "Epoch [2/3], Loss: 1.0653\n",
      "Epoch [2/3], Loss: 1.4719\n",
      "Epoch [2/3], Loss: 1.1804\n",
      "Epoch [2/3], Loss: 1.3211\n",
      "Epoch [2/3], Loss: 0.9224\n",
      "Epoch [2/3], Loss: 1.2423\n",
      "Epoch [2/3], Loss: 1.1908\n",
      "Epoch [2/3], Loss: 1.3739\n",
      "Epoch [2/3], Loss: 1.2348\n",
      "Epoch [2/3], Loss: 1.0396\n",
      "Epoch [2/3], Loss: 1.1087\n",
      "Epoch [2/3], Loss: 1.0893\n",
      "Epoch [2/3], Loss: 1.3071\n",
      "Epoch [2/3], Loss: 1.4251\n",
      "Epoch [2/3], Loss: 1.0168\n",
      "Epoch [2/3], Loss: 1.4150\n",
      "Epoch [2/3], Loss: 1.0603\n",
      "Epoch [2/3], Loss: 1.5599\n",
      "Epoch [2/3], Loss: 1.1826\n",
      "Epoch [2/3], Loss: 1.4626\n",
      "Epoch [2/3], Loss: 1.0526\n",
      "Epoch [2/3], Loss: 1.1345\n",
      "Epoch [2/3], Loss: 1.0667\n",
      "Epoch [2/3], Loss: 1.2866\n",
      "Epoch [2/3], Loss: 1.2362\n",
      "Epoch [2/3], Loss: 1.1062\n",
      "Epoch [2/3], Loss: 1.3598\n",
      "Epoch [2/3], Loss: 1.2100\n",
      "Epoch [2/3], Loss: 1.3434\n",
      "Epoch [2/3], Loss: 1.1050\n",
      "Epoch [2/3], Loss: 1.2365\n",
      "Epoch [2/3], Loss: 1.1850\n",
      "Epoch [2/3], Loss: 1.0051\n",
      "Epoch [2/3], Loss: 1.3294\n",
      "Epoch [2/3], Loss: 1.2251\n",
      "Epoch [2/3], Loss: 1.2741\n",
      "Epoch [2/3], Loss: 1.0006\n",
      "Epoch [2/3], Loss: 0.9858\n",
      "Epoch [2/3], Loss: 1.2774\n",
      "Epoch [2/3], Loss: 1.3420\n",
      "Epoch [2/3], Loss: 1.1934\n",
      "Epoch [2/3], Loss: 1.3161\n",
      "Epoch [2/3], Loss: 1.1911\n",
      "Epoch [2/3], Loss: 1.2483\n",
      "Epoch [2/3], Loss: 0.9861\n",
      "Epoch [2/3], Loss: 1.2863\n",
      "Epoch [2/3], Loss: 0.8546\n",
      "Epoch [2/3], Loss: 1.3190\n",
      "Epoch [2/3], Loss: 1.1718\n",
      "Epoch [2/3], Loss: 1.1818\n",
      "Epoch [2/3], Loss: 1.3286\n",
      "Epoch [2/3], Loss: 1.3878\n",
      "Epoch [2/3], Loss: 1.4293\n",
      "Epoch [2/3], Loss: 1.2796\n",
      "Epoch [2/3], Loss: 1.0802\n",
      "Epoch [2/3], Loss: 0.9651\n",
      "Epoch [2/3], Loss: 1.1208\n",
      "Epoch [2/3], Loss: 0.9178\n",
      "Epoch [2/3], Loss: 1.2981\n",
      "Epoch [2/3], Loss: 1.4923\n",
      "Epoch [2/3], Loss: 1.4539\n",
      "Epoch [2/3], Loss: 1.4414\n",
      "Epoch [2/3], Loss: 1.1727\n",
      "Epoch [2/3], Loss: 1.1530\n",
      "Epoch [2/3], Loss: 1.3853\n",
      "Epoch [2/3], Loss: 1.1217\n",
      "Epoch [2/3], Loss: 1.3746\n",
      "Epoch [2/3], Loss: 1.2825\n",
      "Epoch [2/3], Loss: 1.0683\n",
      "Epoch [2/3], Loss: 1.3564\n",
      "Epoch [2/3], Loss: 1.1389\n",
      "Epoch [2/3], Loss: 1.2450\n",
      "Epoch [2/3], Loss: 1.0662\n",
      "Epoch [2/3], Loss: 1.0331\n",
      "Epoch [2/3], Loss: 1.2818\n",
      "Epoch [2/3], Loss: 1.0062\n",
      "Epoch [2/3], Loss: 1.1174\n",
      "Epoch [2/3], Loss: 1.1316\n",
      "Epoch [2/3], Loss: 1.2872\n",
      "Epoch [2/3], Loss: 1.3848\n",
      "Epoch [2/3], Loss: 1.2132\n",
      "Epoch [2/3], Loss: 1.0962\n",
      "Epoch [2/3], Loss: 1.2947\n",
      "Epoch [2/3], Loss: 1.2006\n",
      "Epoch [2/3], Loss: 0.9503\n",
      "Epoch [2/3], Loss: 1.5289\n",
      "Epoch [2/3], Loss: 1.0793\n",
      "Epoch [2/3], Loss: 1.1030\n",
      "Epoch [2/3], Loss: 0.8895\n",
      "Epoch [2/3], Loss: 1.2400\n",
      "Epoch [2/3], Loss: 1.2315\n",
      "Epoch [2/3], Loss: 1.0797\n",
      "Epoch [2/3], Loss: 1.5492\n",
      "Epoch [2/3], Loss: 1.1881\n",
      "Epoch [2/3], Loss: 1.1520\n",
      "Epoch [2/3], Loss: 1.6472\n",
      "Epoch [2/3], Loss: 1.0781\n",
      "Epoch [2/3], Loss: 1.1025\n",
      "Epoch [2/3], Loss: 1.4389\n",
      "Epoch [2/3], Loss: 1.3593\n",
      "Epoch [2/3], Loss: 1.1722\n",
      "Epoch [2/3], Loss: 1.1388\n",
      "Epoch [2/3], Loss: 1.1698\n",
      "Epoch [2/3], Loss: 1.1469\n",
      "Epoch [2/3], Loss: 1.0635\n",
      "Epoch [2/3], Loss: 1.0699\n",
      "Epoch [2/3], Loss: 1.2295\n",
      "Epoch [2/3], Loss: 1.3987\n",
      "Epoch [2/3], Loss: 1.1517\n",
      "Epoch [2/3], Loss: 1.0185\n",
      "Epoch [2/3], Loss: 0.9872\n",
      "Epoch [2/3], Loss: 0.9407\n",
      "Epoch [2/3], Loss: 1.1479\n",
      "Epoch [2/3], Loss: 1.2991\n",
      "Epoch [2/3], Loss: 1.2540\n",
      "Epoch [2/3], Loss: 1.0283\n",
      "Epoch [2/3], Loss: 1.2753\n",
      "Epoch [2/3], Loss: 1.0482\n",
      "Epoch [2/3], Loss: 1.1696\n",
      "Epoch [2/3], Loss: 0.9993\n",
      "Epoch [2/3], Loss: 1.0768\n",
      "Epoch [2/3], Loss: 1.0784\n",
      "Epoch [2/3], Loss: 1.2180\n",
      "Epoch [2/3], Loss: 1.1426\n",
      "Epoch [2/3], Loss: 1.2647\n",
      "Epoch [2/3], Loss: 1.1923\n",
      "Epoch [2/3], Loss: 1.1205\n",
      "Epoch [2/3], Loss: 1.3341\n",
      "Epoch [2/3], Loss: 1.2266\n",
      "Epoch [2/3], Loss: 1.0663\n",
      "Epoch [2/3], Loss: 1.2694\n",
      "Epoch [2/3], Loss: 1.0222\n",
      "Epoch [2/3], Loss: 1.1404\n",
      "Epoch [2/3], Loss: 1.1192\n",
      "Epoch [2/3], Loss: 0.9309\n",
      "Epoch [2/3], Loss: 1.0147\n",
      "Epoch [2/3], Loss: 1.1575\n",
      "Epoch [2/3], Loss: 0.9661\n",
      "Epoch [2/3], Loss: 1.0101\n",
      "Epoch [2/3], Loss: 1.3341\n",
      "Epoch [2/3], Loss: 1.3791\n",
      "Epoch [2/3], Loss: 1.3903\n",
      "Epoch [2/3], Loss: 1.1755\n",
      "Epoch [2/3], Loss: 1.1877\n",
      "Epoch [2/3], Loss: 1.1038\n",
      "Epoch [2/3], Loss: 1.0715\n",
      "Epoch [2/3], Loss: 1.4766\n",
      "Epoch [2/3], Loss: 1.0607\n",
      "Epoch [2/3], Loss: 1.0558\n",
      "Epoch [2/3], Loss: 0.9357\n",
      "Epoch [2/3], Loss: 1.1358\n",
      "Epoch [2/3], Loss: 1.1559\n",
      "Epoch [2/3], Loss: 1.2140\n",
      "Epoch [2/3], Loss: 1.2626\n",
      "Epoch [2/3], Loss: 0.9184\n",
      "Epoch [2/3], Loss: 1.0449\n",
      "Epoch [2/3], Loss: 1.2628\n",
      "Epoch [2/3], Loss: 1.0315\n",
      "Epoch [2/3], Loss: 1.1981\n",
      "Epoch [2/3], Loss: 1.1534\n",
      "Epoch [2/3], Loss: 1.0567\n",
      "Epoch [2/3], Loss: 1.2381\n",
      "Epoch [2/3], Loss: 1.1406\n",
      "Epoch [2/3], Loss: 1.1145\n",
      "Epoch [2/3], Loss: 0.9771\n",
      "Epoch [2/3], Loss: 1.2508\n",
      "Epoch [2/3], Loss: 1.0839\n",
      "Epoch [2/3], Loss: 1.0121\n",
      "Epoch [2/3], Loss: 1.1651\n",
      "Epoch [2/3], Loss: 1.0319\n",
      "Epoch [2/3], Loss: 1.0737\n",
      "Epoch [2/3], Loss: 1.1420\n",
      "Epoch [2/3], Loss: 1.1347\n",
      "Epoch [2/3], Loss: 0.9504\n",
      "Epoch [2/3], Loss: 1.0915\n",
      "Epoch [2/3], Loss: 1.2265\n",
      "Epoch [2/3], Loss: 1.2281\n",
      "Epoch [2/3], Loss: 1.1890\n",
      "Epoch [2/3], Loss: 1.1871\n",
      "Epoch [2/3], Loss: 1.0494\n",
      "Epoch [2/3], Loss: 0.9852\n",
      "Epoch [2/3], Loss: 0.9129\n",
      "Epoch [2/3], Loss: 1.3044\n",
      "Epoch [2/3], Loss: 1.2269\n",
      "Epoch [2/3], Loss: 1.0830\n",
      "Epoch [2/3], Loss: 0.8928\n",
      "Epoch [2/3], Loss: 0.7879\n",
      "Epoch [2/3], Loss: 1.0330\n",
      "Epoch [2/3], Loss: 0.9990\n",
      "Epoch [2/3], Loss: 1.0095\n",
      "Epoch [2/3], Loss: 1.0885\n",
      "Epoch [2/3], Loss: 1.1411\n",
      "Epoch [2/3], Loss: 0.8918\n",
      "Epoch [2/3], Loss: 1.3330\n",
      "Epoch [2/3], Loss: 1.0102\n",
      "Epoch [2/3], Loss: 0.9433\n",
      "Epoch [2/3], Loss: 0.8390\n",
      "Epoch [2/3], Loss: 0.7743\n",
      "Epoch [2/3], Loss: 1.1555\n",
      "Epoch [2/3], Loss: 1.0538\n",
      "Epoch [2/3], Loss: 0.8446\n",
      "Epoch [2/3], Loss: 1.1356\n",
      "Epoch [2/3], Loss: 1.1069\n",
      "Epoch [2/3], Loss: 1.1051\n",
      "Epoch [2/3], Loss: 1.1460\n",
      "Epoch [2/3], Loss: 1.0164\n",
      "Epoch [2/3], Loss: 1.2263\n",
      "Epoch [2/3], Loss: 1.1304\n",
      "Epoch [2/3], Loss: 0.9625\n",
      "Epoch [2/3], Loss: 0.9491\n",
      "Epoch [2/3], Loss: 1.2801\n",
      "Epoch [2/3], Loss: 1.1611\n",
      "Epoch [2/3], Loss: 1.1098\n",
      "Epoch [2/3], Loss: 0.8742\n",
      "Epoch [2/3], Loss: 0.9986\n",
      "Epoch [2/3], Loss: 1.1496\n",
      "Epoch [2/3], Loss: 1.0887\n",
      "Epoch [2/3], Loss: 0.9264\n",
      "Epoch [2/3], Loss: 0.9562\n",
      "Epoch [2/3], Loss: 1.3659\n",
      "Epoch [2/3], Loss: 1.1049\n",
      "Epoch [2/3], Loss: 0.9033\n",
      "Epoch [2/3], Loss: 0.8773\n",
      "Epoch [2/3], Loss: 1.0190\n",
      "Epoch [2/3], Loss: 1.0393\n",
      "Epoch [2/3], Loss: 0.7581\n",
      "Epoch [2/3], Loss: 1.1300\n",
      "Epoch [2/3], Loss: 0.6929\n",
      "Epoch [2/3], Loss: 1.1868\n",
      "Epoch [2/3], Loss: 0.9667\n",
      "Epoch [2/3], Loss: 0.9243\n",
      "Epoch [2/3], Loss: 1.0333\n",
      "Epoch [2/3], Loss: 0.9495\n",
      "Epoch [2/3], Loss: 1.0519\n",
      "Epoch [2/3], Loss: 0.9006\n",
      "Epoch [2/3], Loss: 0.7518\n",
      "Epoch [2/3], Loss: 1.0962\n",
      "Epoch [2/3], Loss: 0.8426\n",
      "Epoch [2/3], Loss: 1.4978\n",
      "Epoch [2/3], Loss: 1.1630\n",
      "Epoch [2/3], Loss: 1.0794\n",
      "Epoch [2/3], Loss: 0.8178\n",
      "Epoch [2/3], Loss: 0.9302\n",
      "Epoch [2/3], Loss: 0.7622\n",
      "Epoch [2/3], Loss: 1.0356\n",
      "Epoch [2/3], Loss: 0.9495\n",
      "Epoch [2/3], Loss: 0.9272\n",
      "Epoch [2/3], Loss: 1.2323\n",
      "Epoch [2/3], Loss: 1.1163\n",
      "Epoch [2/3], Loss: 0.8022\n",
      "Epoch [2/3], Loss: 1.0583\n",
      "Epoch [2/3], Loss: 0.9197\n",
      "Epoch [2/3], Loss: 0.9901\n",
      "Epoch [2/3], Loss: 1.2764\n",
      "Epoch [2/3], Loss: 0.9013\n",
      "Epoch [2/3], Loss: 1.0588\n",
      "Epoch [2/3], Loss: 1.0622\n",
      "Epoch [2/3], Loss: 0.9557\n",
      "Epoch [2/3], Loss: 1.0713\n",
      "Epoch [2/3], Loss: 0.9458\n",
      "Epoch [2/3], Loss: 1.1211\n",
      "Epoch [2/3], Loss: 0.9844\n",
      "Epoch [2/3], Loss: 0.9502\n",
      "Epoch [2/3], Loss: 0.8324\n",
      "Epoch [2/3], Loss: 0.9699\n",
      "Epoch [2/3], Loss: 0.7950\n",
      "Epoch [2/3], Loss: 0.9248\n",
      "Epoch [2/3], Loss: 1.0202\n",
      "Epoch [2/3], Loss: 0.9648\n",
      "Epoch [2/3], Loss: 0.9338\n",
      "Epoch [2/3], Loss: 0.9511\n",
      "Epoch [2/3], Loss: 1.0108\n",
      "Epoch [2/3], Loss: 0.9438\n",
      "Epoch [2/3], Loss: 0.8803\n",
      "Epoch [2/3], Loss: 1.0397\n",
      "Epoch [2/3], Loss: 0.8199\n",
      "Epoch [2/3], Loss: 0.8442\n",
      "Epoch [2/3], Loss: 1.2595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.8717\n",
      "Epoch [2/3], Loss: 0.8465\n",
      "Epoch [2/3], Loss: 0.8088\n",
      "Epoch [2/3], Loss: 1.0987\n",
      "Epoch [2/3], Loss: 0.8607\n",
      "Epoch [2/3], Loss: 1.1171\n",
      "Epoch [2/3], Loss: 0.9617\n",
      "Epoch [2/3], Loss: 0.7910\n",
      "Epoch [2/3], Loss: 1.0981\n",
      "Epoch [2/3], Loss: 0.8484\n",
      "Epoch [2/3], Loss: 1.0994\n",
      "Epoch [2/3], Loss: 0.9937\n",
      "Epoch [2/3], Loss: 1.0425\n",
      "Epoch [2/3], Loss: 1.0136\n",
      "Epoch [2/3], Loss: 0.8066\n",
      "Epoch [2/3], Loss: 1.0590\n",
      "Epoch [2/3], Loss: 1.0621\n",
      "Epoch [2/3], Loss: 0.8218\n",
      "Epoch [2/3], Loss: 0.8358\n",
      "Epoch [2/3], Loss: 0.7269\n",
      "Epoch [2/3], Loss: 1.1048\n",
      "Epoch [2/3], Loss: 0.9721\n",
      "Epoch [2/3], Loss: 1.1078\n",
      "Epoch [2/3], Loss: 1.2035\n",
      "Epoch [2/3], Loss: 0.9647\n",
      "Epoch [2/3], Loss: 1.0213\n",
      "Epoch [2/3], Loss: 1.0115\n",
      "Epoch [2/3], Loss: 0.7829\n",
      "Epoch [2/3], Loss: 1.0889\n",
      "Epoch [2/3], Loss: 0.8552\n",
      "Epoch [2/3], Loss: 1.1361\n",
      "Epoch [2/3], Loss: 0.8599\n",
      "Epoch [2/3], Loss: 0.9533\n",
      "Epoch [2/3], Loss: 1.1089\n",
      "Epoch [2/3], Loss: 0.9056\n",
      "Epoch [2/3], Loss: 0.9646\n",
      "Epoch [2/3], Loss: 0.7646\n",
      "Epoch [2/3], Loss: 0.6326\n",
      "Epoch [2/3], Loss: 0.8580\n",
      "Epoch [2/3], Loss: 0.8325\n",
      "Epoch [2/3], Loss: 0.7406\n",
      "Epoch [2/3], Loss: 1.0037\n",
      "Epoch [2/3], Loss: 0.9123\n",
      "Epoch [2/3], Loss: 0.8086\n",
      "Epoch [2/3], Loss: 1.1208\n",
      "Epoch [2/3], Loss: 0.6900\n",
      "Epoch [2/3], Loss: 1.0207\n",
      "Epoch [2/3], Loss: 0.8344\n",
      "Epoch [2/3], Loss: 1.0799\n",
      "Epoch [2/3], Loss: 0.9549\n",
      "Epoch [2/3], Loss: 0.6670\n",
      "Epoch [2/3], Loss: 0.9892\n",
      "Epoch [2/3], Loss: 0.6948\n",
      "Epoch [2/3], Loss: 0.9574\n",
      "Epoch [2/3], Loss: 1.2404\n",
      "Epoch [2/3], Loss: 0.8652\n",
      "Epoch [2/3], Loss: 0.7234\n",
      "Epoch [2/3], Loss: 0.9171\n",
      "Epoch [2/3], Loss: 1.0097\n",
      "Epoch [2/3], Loss: 0.8309\n",
      "Epoch [2/3], Loss: 0.8391\n",
      "Epoch [2/3], Loss: 0.7470\n",
      "Epoch [2/3], Loss: 0.6580\n",
      "Epoch [2/3], Loss: 0.8096\n",
      "Epoch [2/3], Loss: 0.9148\n",
      "Epoch [2/3], Loss: 0.9748\n",
      "Epoch [2/3], Loss: 0.8036\n",
      "Epoch [2/3], Loss: 0.7018\n",
      "Epoch [2/3], Loss: 0.9891\n",
      "Epoch [2/3], Loss: 1.0138\n",
      "Epoch [2/3], Loss: 1.0223\n",
      "Epoch [2/3], Loss: 1.0887\n",
      "Epoch [2/3], Loss: 0.9652\n",
      "Epoch [2/3], Loss: 0.8828\n",
      "Epoch [2/3], Loss: 0.7808\n",
      "Epoch [2/3], Loss: 0.8957\n",
      "Epoch [2/3], Loss: 0.7020\n",
      "Epoch [2/3], Loss: 0.8257\n",
      "Epoch [2/3], Loss: 1.0439\n",
      "Epoch [2/3], Loss: 0.7303\n",
      "Epoch [2/3], Loss: 1.0377\n",
      "Epoch [2/3], Loss: 0.9594\n",
      "Epoch [2/3], Loss: 0.7527\n",
      "Epoch [2/3], Loss: 1.0427\n",
      "Epoch [2/3], Loss: 0.7168\n",
      "Epoch [2/3], Loss: 0.6361\n",
      "Epoch [2/3], Loss: 0.8611\n",
      "Epoch [2/3], Loss: 0.6180\n",
      "Epoch [2/3], Loss: 0.6853\n",
      "Epoch [2/3], Loss: 0.7665\n",
      "Epoch [2/3], Loss: 0.8160\n",
      "Epoch [2/3], Loss: 0.9277\n",
      "Epoch [2/3], Loss: 0.6960\n",
      "Epoch [2/3], Loss: 0.8459\n",
      "Epoch [2/3], Loss: 0.9338\n",
      "Epoch [2/3], Loss: 1.1620\n",
      "Epoch [2/3], Loss: 0.7986\n",
      "Epoch [2/3], Loss: 0.8734\n",
      "Epoch [2/3], Loss: 0.8803\n",
      "Epoch [2/3], Loss: 0.8345\n",
      "Epoch [2/3], Loss: 0.8167\n",
      "Epoch [2/3], Loss: 0.8736\n",
      "Epoch [2/3], Loss: 0.7964\n",
      "Epoch [2/3], Loss: 0.7975\n",
      "Epoch [2/3], Loss: 0.9370\n",
      "Epoch [2/3], Loss: 0.9026\n",
      "Epoch [2/3], Loss: 0.6791\n",
      "Epoch [2/3], Loss: 0.8500\n",
      "Epoch [2/3], Loss: 0.7157\n",
      "Epoch [2/3], Loss: 0.8366\n",
      "Epoch [2/3], Loss: 0.8181\n",
      "Epoch [2/3], Loss: 0.8293\n",
      "Epoch [2/3], Loss: 0.6498\n",
      "Epoch [2/3], Loss: 0.6517\n",
      "Epoch [2/3], Loss: 0.9077\n",
      "Epoch [2/3], Loss: 0.7684\n",
      "Epoch [2/3], Loss: 0.9114\n",
      "Epoch [2/3], Loss: 0.8601\n",
      "Epoch [2/3], Loss: 0.5805\n",
      "Epoch [2/3], Loss: 0.7063\n",
      "Epoch [2/3], Loss: 0.7212\n",
      "Epoch [2/3], Loss: 0.7075\n",
      "Epoch [2/3], Loss: 0.7836\n",
      "Epoch [2/3], Loss: 0.8011\n",
      "Epoch [2/3], Loss: 0.8774\n",
      "Epoch [2/3], Loss: 0.9457\n",
      "Epoch [2/3], Loss: 0.9041\n",
      "Epoch [2/3], Loss: 0.6286\n",
      "Epoch [2/3], Loss: 0.8225\n",
      "Epoch [2/3], Loss: 0.6098\n",
      "Epoch [2/3], Loss: 0.8505\n",
      "Epoch [2/3], Loss: 1.0315\n",
      "Epoch [2/3], Loss: 0.9247\n",
      "Epoch [2/3], Loss: 0.7254\n",
      "Epoch [2/3], Loss: 1.1298\n",
      "Epoch [2/3], Loss: 0.8576\n",
      "Epoch [2/3], Loss: 0.7738\n",
      "Epoch [2/3], Loss: 0.8680\n",
      "Epoch [2/3], Loss: 0.8098\n",
      "Epoch [2/3], Loss: 0.8883\n",
      "Epoch [2/3], Loss: 0.6493\n",
      "Epoch [2/3], Loss: 0.9179\n",
      "Epoch [2/3], Loss: 0.9502\n",
      "Epoch [2/3], Loss: 0.7852\n",
      "Epoch [2/3], Loss: 0.7545\n",
      "Epoch [2/3], Loss: 0.6724\n",
      "Epoch [2/3], Loss: 0.9915\n",
      "Epoch [2/3], Loss: 0.8297\n",
      "Epoch [2/3], Loss: 0.9048\n",
      "Epoch [2/3], Loss: 0.6046\n",
      "Epoch [2/3], Loss: 0.7782\n",
      "Epoch [2/3], Loss: 0.6847\n",
      "Epoch [2/3], Loss: 0.6831\n",
      "Epoch [2/3], Loss: 0.8635\n",
      "Epoch [2/3], Loss: 0.7153\n",
      "Epoch [2/3], Loss: 0.9289\n",
      "Epoch [2/3], Loss: 0.6619\n",
      "Epoch [2/3], Loss: 0.9699\n",
      "Epoch [2/3], Loss: 0.8110\n",
      "Epoch [2/3], Loss: 0.8434\n",
      "Epoch [2/3], Loss: 0.8748\n",
      "Epoch [2/3], Loss: 0.7806\n",
      "Epoch [2/3], Loss: 0.8599\n",
      "Epoch [2/3], Loss: 0.6172\n",
      "Epoch [2/3], Loss: 0.4102\n",
      "Epoch [2/3], Loss: 0.7784\n",
      "Epoch [2/3], Loss: 0.8671\n",
      "Epoch [2/3], Loss: 1.0347\n",
      "Epoch [2/3], Loss: 0.8644\n",
      "Epoch [2/3], Loss: 0.5736\n",
      "Epoch [2/3], Loss: 0.7317\n",
      "Epoch [2/3], Loss: 0.8235\n",
      "Epoch [2/3], Loss: 0.7191\n",
      "Epoch [2/3], Loss: 0.6714\n",
      "Epoch [2/3], Loss: 0.8211\n",
      "Epoch [2/3], Loss: 0.7716\n",
      "Epoch [2/3], Loss: 1.0333\n",
      "Epoch [2/3], Loss: 0.9214\n",
      "Epoch [2/3], Loss: 0.8810\n",
      "Epoch [2/3], Loss: 0.5743\n",
      "Epoch [2/3], Loss: 0.6027\n",
      "Epoch [2/3], Loss: 0.7670\n",
      "Epoch [2/3], Loss: 1.0262\n",
      "Epoch [2/3], Loss: 0.5520\n",
      "Epoch [2/3], Loss: 0.7765\n",
      "Epoch [2/3], Loss: 0.7971\n",
      "Epoch [2/3], Loss: 0.7146\n",
      "Epoch [2/3], Loss: 0.7148\n",
      "Epoch [2/3], Loss: 0.7073\n",
      "Epoch [2/3], Loss: 0.9600\n",
      "Epoch [2/3], Loss: 0.6709\n",
      "Epoch [2/3], Loss: 0.8112\n",
      "Epoch [2/3], Loss: 0.9030\n",
      "Epoch [2/3], Loss: 0.9180\n",
      "Epoch [2/3], Loss: 0.9217\n",
      "Epoch [2/3], Loss: 0.6116\n",
      "Epoch [2/3], Loss: 0.6683\n",
      "Epoch [2/3], Loss: 0.8873\n",
      "Epoch [2/3], Loss: 0.9873\n",
      "Epoch [2/3], Loss: 0.6590\n",
      "Epoch [2/3], Loss: 0.8397\n",
      "Epoch [2/3], Loss: 0.5905\n",
      "Epoch [2/3], Loss: 0.8148\n",
      "Epoch [2/3], Loss: 0.6524\n",
      "Epoch [2/3], Loss: 1.0011\n",
      "Epoch [2/3], Loss: 1.1299\n",
      "Epoch [2/3], Loss: 0.9191\n",
      "Epoch [2/3], Loss: 0.8858\n",
      "Epoch [2/3], Loss: 0.7679\n",
      "Epoch [2/3], Loss: 0.7913\n",
      "Epoch [2/3], Loss: 0.8294\n",
      "Epoch [2/3], Loss: 0.8709\n",
      "Epoch [2/3], Loss: 0.6999\n",
      "Epoch [2/3], Loss: 0.8664\n",
      "Epoch [2/3], Loss: 0.9307\n",
      "Epoch [2/3], Loss: 0.5745\n",
      "Epoch [2/3], Loss: 0.8151\n",
      "Epoch [2/3], Loss: 0.7941\n",
      "Epoch [2/3], Loss: 1.0123\n",
      "Epoch [2/3], Loss: 0.6884\n",
      "Epoch [2/3], Loss: 0.7316\n",
      "Epoch [2/3], Loss: 0.5189\n",
      "Epoch [2/3], Loss: 1.0353\n",
      "Epoch [2/3], Loss: 0.6431\n",
      "Epoch [2/3], Loss: 0.6581\n",
      "Epoch [2/3], Loss: 0.7127\n",
      "Epoch [2/3], Loss: 0.9154\n",
      "Epoch [2/3], Loss: 0.6957\n",
      "Epoch [2/3], Loss: 0.9736\n",
      "Epoch [2/3], Loss: 0.5696\n",
      "Epoch [2/3], Loss: 1.0739\n",
      "Epoch [2/3], Loss: 0.6536\n",
      "Epoch [2/3], Loss: 1.0082\n",
      "Epoch [2/3], Loss: 0.7532\n",
      "Epoch [2/3], Loss: 0.6802\n",
      "Epoch [2/3], Loss: 0.9369\n",
      "Epoch [2/3], Loss: 0.5774\n",
      "Epoch [2/3], Loss: 0.7048\n",
      "Epoch [2/3], Loss: 0.5450\n",
      "Epoch [2/3], Loss: 0.7526\n",
      "Epoch [2/3], Loss: 0.7089\n",
      "Epoch [2/3], Loss: 0.5270\n",
      "Epoch [2/3], Loss: 0.4772\n",
      "Epoch [2/3], Loss: 0.5793\n",
      "Epoch [2/3], Loss: 0.7205\n",
      "Epoch [2/3], Loss: 0.5999\n",
      "Epoch [2/3], Loss: 0.5173\n",
      "Epoch [2/3], Loss: 0.7398\n",
      "Epoch [2/3], Loss: 0.6615\n",
      "Epoch [2/3], Loss: 0.8052\n",
      "Epoch [2/3], Loss: 0.6983\n",
      "Epoch [2/3], Loss: 0.7096\n",
      "Epoch [2/3], Loss: 0.8825\n",
      "Epoch [2/3], Loss: 0.7129\n",
      "Epoch [2/3], Loss: 0.6800\n",
      "Epoch [2/3], Loss: 0.5478\n",
      "Epoch [2/3], Loss: 0.4375\n",
      "Epoch [2/3], Loss: 0.6411\n",
      "Epoch [2/3], Loss: 0.9626\n",
      "Epoch [2/3], Loss: 0.8576\n",
      "Epoch [2/3], Loss: 0.9087\n",
      "Epoch [2/3], Loss: 0.9014\n",
      "Epoch [2/3], Loss: 0.6510\n",
      "Epoch [2/3], Loss: 0.6559\n",
      "Epoch [2/3], Loss: 0.7314\n",
      "Epoch [2/3], Loss: 0.7222\n",
      "Epoch [2/3], Loss: 0.7341\n",
      "Epoch [2/3], Loss: 0.7252\n",
      "Epoch [2/3], Loss: 0.8754\n",
      "Epoch [2/3], Loss: 0.6962\n",
      "Epoch [2/3], Loss: 0.7393\n",
      "Epoch [2/3], Loss: 0.8570\n",
      "Epoch [2/3], Loss: 0.8231\n",
      "Epoch [2/3], Loss: 0.8934\n",
      "Epoch [2/3], Loss: 0.6927\n",
      "Epoch [2/3], Loss: 0.6449\n",
      "Epoch [2/3], Loss: 0.4941\n",
      "Epoch [2/3], Loss: 0.5918\n",
      "Epoch [2/3], Loss: 0.7007\n",
      "Epoch [2/3], Loss: 0.6329\n",
      "Epoch [2/3], Loss: 0.7614\n",
      "Epoch [2/3], Loss: 0.5847\n",
      "Epoch [2/3], Loss: 0.7718\n",
      "Epoch [2/3], Loss: 0.6988\n",
      "Epoch [2/3], Loss: 0.5484\n",
      "Epoch [2/3], Loss: 0.7830\n",
      "Epoch [2/3], Loss: 0.6804\n",
      "Epoch [2/3], Loss: 0.7838\n",
      "Epoch [2/3], Loss: 0.4897\n",
      "Epoch [2/3], Loss: 0.7383\n",
      "Epoch [2/3], Loss: 1.0126\n",
      "Epoch [2/3], Loss: 0.5652\n",
      "Epoch [2/3], Loss: 0.8759\n",
      "Epoch [2/3], Loss: 0.9167\n",
      "Epoch [2/3], Loss: 0.7426\n",
      "Epoch [2/3], Loss: 0.5957\n",
      "Epoch [2/3], Loss: 0.6983\n",
      "Epoch [2/3], Loss: 0.6158\n",
      "Epoch [2/3], Loss: 0.6223\n",
      "Epoch [2/3], Loss: 0.7220\n",
      "Epoch [2/3], Loss: 0.6202\n",
      "Epoch [2/3], Loss: 0.8173\n",
      "Epoch [2/3], Loss: 0.7953\n",
      "Epoch [2/3], Loss: 0.7822\n",
      "Epoch [2/3], Loss: 0.7344\n",
      "Epoch [2/3], Loss: 0.5606\n",
      "Epoch [2/3], Loss: 0.7207\n",
      "Epoch [2/3], Loss: 0.7349\n",
      "Epoch [2/3], Loss: 0.4706\n",
      "Epoch [2/3], Loss: 0.4285\n",
      "Epoch [2/3], Loss: 0.5202\n",
      "Epoch [2/3], Loss: 0.4033\n",
      "Epoch [2/3], Loss: 0.5315\n",
      "Epoch [2/3], Loss: 0.8166\n",
      "Epoch [2/3], Loss: 0.8719\n",
      "Epoch [2/3], Loss: 0.6031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.7034\n",
      "Epoch [2/3], Loss: 0.5000\n",
      "Epoch [2/3], Loss: 0.6171\n",
      "Epoch [2/3], Loss: 0.6355\n",
      "Epoch [2/3], Loss: 0.7399\n",
      "Epoch [2/3], Loss: 0.7825\n",
      "Epoch [2/3], Loss: 0.6232\n",
      "Epoch [2/3], Loss: 0.8022\n",
      "Epoch [2/3], Loss: 0.8407\n",
      "Epoch [2/3], Loss: 0.8550\n",
      "Epoch [2/3], Loss: 0.8065\n",
      "Epoch [2/3], Loss: 0.6835\n",
      "Epoch [2/3], Loss: 0.4203\n",
      "Epoch [2/3], Loss: 0.7389\n",
      "Epoch [2/3], Loss: 0.6444\n",
      "Epoch [2/3], Loss: 0.8570\n",
      "Epoch [2/3], Loss: 0.7228\n",
      "Epoch [2/3], Loss: 0.5136\n",
      "Epoch [2/3], Loss: 0.5136\n",
      "Epoch [3/3], Loss: 0.6355\n",
      "Epoch [3/3], Loss: 0.4734\n",
      "Epoch [3/3], Loss: 0.3853\n",
      "Epoch [3/3], Loss: 0.5041\n",
      "Epoch [3/3], Loss: 0.6442\n",
      "Epoch [3/3], Loss: 0.4998\n",
      "Epoch [3/3], Loss: 0.6934\n",
      "Epoch [3/3], Loss: 0.4197\n",
      "Epoch [3/3], Loss: 0.3526\n",
      "Epoch [3/3], Loss: 0.5827\n",
      "Epoch [3/3], Loss: 0.3365\n",
      "Epoch [3/3], Loss: 0.5989\n",
      "Epoch [3/3], Loss: 0.4228\n",
      "Epoch [3/3], Loss: 0.4631\n",
      "Epoch [3/3], Loss: 0.4899\n",
      "Epoch [3/3], Loss: 0.6022\n",
      "Epoch [3/3], Loss: 0.3915\n",
      "Epoch [3/3], Loss: 0.3798\n",
      "Epoch [3/3], Loss: 0.4204\n",
      "Epoch [3/3], Loss: 0.3875\n",
      "Epoch [3/3], Loss: 0.4582\n",
      "Epoch [3/3], Loss: 0.3667\n",
      "Epoch [3/3], Loss: 0.3759\n",
      "Epoch [3/3], Loss: 0.2856\n",
      "Epoch [3/3], Loss: 0.4897\n",
      "Epoch [3/3], Loss: 0.5738\n",
      "Epoch [3/3], Loss: 0.2408\n",
      "Epoch [3/3], Loss: 0.4071\n",
      "Epoch [3/3], Loss: 0.4693\n",
      "Epoch [3/3], Loss: 0.5228\n",
      "Epoch [3/3], Loss: 0.4400\n",
      "Epoch [3/3], Loss: 0.4078\n",
      "Epoch [3/3], Loss: 0.5145\n",
      "Epoch [3/3], Loss: 0.3491\n",
      "Epoch [3/3], Loss: 0.5459\n",
      "Epoch [3/3], Loss: 0.5522\n",
      "Epoch [3/3], Loss: 0.4459\n",
      "Epoch [3/3], Loss: 0.5136\n",
      "Epoch [3/3], Loss: 0.5225\n",
      "Epoch [3/3], Loss: 0.4299\n",
      "Epoch [3/3], Loss: 0.5715\n",
      "Epoch [3/3], Loss: 0.6043\n",
      "Epoch [3/3], Loss: 0.4590\n",
      "Epoch [3/3], Loss: 0.4288\n",
      "Epoch [3/3], Loss: 0.5766\n",
      "Epoch [3/3], Loss: 0.3567\n",
      "Epoch [3/3], Loss: 0.3331\n",
      "Epoch [3/3], Loss: 0.6947\n",
      "Epoch [3/3], Loss: 0.3331\n",
      "Epoch [3/3], Loss: 0.5604\n",
      "Epoch [3/3], Loss: 0.3178\n",
      "Epoch [3/3], Loss: 0.5041\n",
      "Epoch [3/3], Loss: 0.5331\n",
      "Epoch [3/3], Loss: 0.3437\n",
      "Epoch [3/3], Loss: 0.8235\n",
      "Epoch [3/3], Loss: 0.4733\n",
      "Epoch [3/3], Loss: 0.5473\n",
      "Epoch [3/3], Loss: 0.5397\n",
      "Epoch [3/3], Loss: 0.3951\n",
      "Epoch [3/3], Loss: 0.5134\n",
      "Epoch [3/3], Loss: 0.4071\n",
      "Epoch [3/3], Loss: 0.3772\n",
      "Epoch [3/3], Loss: 0.4262\n",
      "Epoch [3/3], Loss: 0.4597\n",
      "Epoch [3/3], Loss: 0.3401\n",
      "Epoch [3/3], Loss: 0.5367\n",
      "Epoch [3/3], Loss: 0.4596\n",
      "Epoch [3/3], Loss: 0.3453\n",
      "Epoch [3/3], Loss: 0.3525\n",
      "Epoch [3/3], Loss: 0.3443\n",
      "Epoch [3/3], Loss: 0.7980\n",
      "Epoch [3/3], Loss: 0.3390\n",
      "Epoch [3/3], Loss: 0.4093\n",
      "Epoch [3/3], Loss: 0.4295\n",
      "Epoch [3/3], Loss: 0.5510\n",
      "Epoch [3/3], Loss: 0.5383\n",
      "Epoch [3/3], Loss: 0.4632\n",
      "Epoch [3/3], Loss: 0.3526\n",
      "Epoch [3/3], Loss: 0.4146\n",
      "Epoch [3/3], Loss: 0.3887\n",
      "Epoch [3/3], Loss: 0.7491\n",
      "Epoch [3/3], Loss: 0.4816\n",
      "Epoch [3/3], Loss: 0.6241\n",
      "Epoch [3/3], Loss: 0.5225\n",
      "Epoch [3/3], Loss: 0.3482\n",
      "Epoch [3/3], Loss: 0.4680\n",
      "Epoch [3/3], Loss: 0.5006\n",
      "Epoch [3/3], Loss: 0.3263\n",
      "Epoch [3/3], Loss: 0.4790\n",
      "Epoch [3/3], Loss: 0.4838\n",
      "Epoch [3/3], Loss: 0.4656\n",
      "Epoch [3/3], Loss: 0.2787\n",
      "Epoch [3/3], Loss: 0.4967\n",
      "Epoch [3/3], Loss: 0.3505\n",
      "Epoch [3/3], Loss: 0.5237\n",
      "Epoch [3/3], Loss: 0.4110\n",
      "Epoch [3/3], Loss: 0.4931\n",
      "Epoch [3/3], Loss: 0.6640\n",
      "Epoch [3/3], Loss: 0.6332\n",
      "Epoch [3/3], Loss: 0.5303\n",
      "Epoch [3/3], Loss: 0.5476\n",
      "Epoch [3/3], Loss: 0.5050\n",
      "Epoch [3/3], Loss: 0.4471\n",
      "Epoch [3/3], Loss: 0.4128\n",
      "Epoch [3/3], Loss: 0.4125\n",
      "Epoch [3/3], Loss: 0.3927\n",
      "Epoch [3/3], Loss: 0.3835\n",
      "Epoch [3/3], Loss: 0.6036\n",
      "Epoch [3/3], Loss: 0.3294\n",
      "Epoch [3/3], Loss: 0.4955\n",
      "Epoch [3/3], Loss: 0.3883\n",
      "Epoch [3/3], Loss: 0.4055\n",
      "Epoch [3/3], Loss: 0.4783\n",
      "Epoch [3/3], Loss: 0.5720\n",
      "Epoch [3/3], Loss: 0.4302\n",
      "Epoch [3/3], Loss: 0.4482\n",
      "Epoch [3/3], Loss: 0.4193\n",
      "Epoch [3/3], Loss: 0.4404\n",
      "Epoch [3/3], Loss: 0.5764\n",
      "Epoch [3/3], Loss: 0.6086\n",
      "Epoch [3/3], Loss: 0.4472\n",
      "Epoch [3/3], Loss: 0.3699\n",
      "Epoch [3/3], Loss: 0.4576\n",
      "Epoch [3/3], Loss: 0.5352\n",
      "Epoch [3/3], Loss: 0.4181\n",
      "Epoch [3/3], Loss: 0.5626\n",
      "Epoch [3/3], Loss: 0.6244\n",
      "Epoch [3/3], Loss: 0.2922\n",
      "Epoch [3/3], Loss: 0.7025\n",
      "Epoch [3/3], Loss: 0.3297\n",
      "Epoch [3/3], Loss: 0.2294\n",
      "Epoch [3/3], Loss: 0.4893\n",
      "Epoch [3/3], Loss: 0.4950\n",
      "Epoch [3/3], Loss: 0.3985\n",
      "Epoch [3/3], Loss: 0.5039\n",
      "Epoch [3/3], Loss: 0.4717\n",
      "Epoch [3/3], Loss: 0.4604\n",
      "Epoch [3/3], Loss: 0.4501\n",
      "Epoch [3/3], Loss: 0.5090\n",
      "Epoch [3/3], Loss: 0.5350\n",
      "Epoch [3/3], Loss: 0.3754\n",
      "Epoch [3/3], Loss: 0.2744\n",
      "Epoch [3/3], Loss: 0.4969\n",
      "Epoch [3/3], Loss: 0.4938\n",
      "Epoch [3/3], Loss: 0.5498\n",
      "Epoch [3/3], Loss: 0.5429\n",
      "Epoch [3/3], Loss: 0.3445\n",
      "Epoch [3/3], Loss: 0.6382\n",
      "Epoch [3/3], Loss: 0.4562\n",
      "Epoch [3/3], Loss: 0.4518\n",
      "Epoch [3/3], Loss: 0.5517\n",
      "Epoch [3/3], Loss: 0.5042\n",
      "Epoch [3/3], Loss: 0.5061\n",
      "Epoch [3/3], Loss: 0.4079\n",
      "Epoch [3/3], Loss: 0.6133\n",
      "Epoch [3/3], Loss: 0.4572\n",
      "Epoch [3/3], Loss: 0.5099\n",
      "Epoch [3/3], Loss: 0.5867\n",
      "Epoch [3/3], Loss: 0.4053\n",
      "Epoch [3/3], Loss: 0.4542\n",
      "Epoch [3/3], Loss: 0.9920\n",
      "Epoch [3/3], Loss: 0.5649\n",
      "Epoch [3/3], Loss: 0.2220\n",
      "Epoch [3/3], Loss: 0.5785\n",
      "Epoch [3/3], Loss: 0.4879\n",
      "Epoch [3/3], Loss: 0.6432\n",
      "Epoch [3/3], Loss: 0.6951\n",
      "Epoch [3/3], Loss: 0.5113\n",
      "Epoch [3/3], Loss: 0.5020\n",
      "Epoch [3/3], Loss: 0.4466\n",
      "Epoch [3/3], Loss: 0.5051\n",
      "Epoch [3/3], Loss: 0.4066\n",
      "Epoch [3/3], Loss: 0.4649\n",
      "Epoch [3/3], Loss: 0.5216\n",
      "Epoch [3/3], Loss: 0.3820\n",
      "Epoch [3/3], Loss: 0.2733\n",
      "Epoch [3/3], Loss: 0.4763\n",
      "Epoch [3/3], Loss: 0.5667\n",
      "Epoch [3/3], Loss: 0.3678\n",
      "Epoch [3/3], Loss: 0.5523\n",
      "Epoch [3/3], Loss: 0.7621\n",
      "Epoch [3/3], Loss: 0.5611\n",
      "Epoch [3/3], Loss: 0.4620\n",
      "Epoch [3/3], Loss: 0.4049\n",
      "Epoch [3/3], Loss: 0.5439\n",
      "Epoch [3/3], Loss: 0.5920\n",
      "Epoch [3/3], Loss: 0.4961\n",
      "Epoch [3/3], Loss: 0.3307\n",
      "Epoch [3/3], Loss: 1.0673\n",
      "Epoch [3/3], Loss: 0.5010\n",
      "Epoch [3/3], Loss: 0.5601\n",
      "Epoch [3/3], Loss: 0.8788\n",
      "Epoch [3/3], Loss: 0.4123\n",
      "Epoch [3/3], Loss: 0.5047\n",
      "Epoch [3/3], Loss: 0.4347\n",
      "Epoch [3/3], Loss: 0.3420\n",
      "Epoch [3/3], Loss: 0.5647\n",
      "Epoch [3/3], Loss: 0.4841\n",
      "Epoch [3/3], Loss: 0.5158\n",
      "Epoch [3/3], Loss: 0.3519\n",
      "Epoch [3/3], Loss: 0.4786\n",
      "Epoch [3/3], Loss: 0.2973\n",
      "Epoch [3/3], Loss: 0.6137\n",
      "Epoch [3/3], Loss: 0.5336\n",
      "Epoch [3/3], Loss: 0.4580\n",
      "Epoch [3/3], Loss: 0.5586\n",
      "Epoch [3/3], Loss: 0.5834\n",
      "Epoch [3/3], Loss: 0.3880\n",
      "Epoch [3/3], Loss: 0.6188\n",
      "Epoch [3/3], Loss: 0.5227\n",
      "Epoch [3/3], Loss: 0.5388\n",
      "Epoch [3/3], Loss: 0.5597\n",
      "Epoch [3/3], Loss: 0.5366\n",
      "Epoch [3/3], Loss: 0.4163\n",
      "Epoch [3/3], Loss: 0.5657\n",
      "Epoch [3/3], Loss: 0.3422\n",
      "Epoch [3/3], Loss: 0.7463\n",
      "Epoch [3/3], Loss: 0.4963\n",
      "Epoch [3/3], Loss: 0.4054\n",
      "Epoch [3/3], Loss: 0.2088\n",
      "Epoch [3/3], Loss: 0.4881\n",
      "Epoch [3/3], Loss: 0.5780\n",
      "Epoch [3/3], Loss: 0.4204\n",
      "Epoch [3/3], Loss: 0.5791\n",
      "Epoch [3/3], Loss: 0.4183\n",
      "Epoch [3/3], Loss: 0.5029\n",
      "Epoch [3/3], Loss: 0.4467\n",
      "Epoch [3/3], Loss: 0.3312\n",
      "Epoch [3/3], Loss: 0.3914\n",
      "Epoch [3/3], Loss: 0.5301\n",
      "Epoch [3/3], Loss: 0.5259\n",
      "Epoch [3/3], Loss: 0.2322\n",
      "Epoch [3/3], Loss: 0.4724\n",
      "Epoch [3/3], Loss: 0.3618\n",
      "Epoch [3/3], Loss: 0.6365\n",
      "Epoch [3/3], Loss: 0.5062\n",
      "Epoch [3/3], Loss: 0.4308\n",
      "Epoch [3/3], Loss: 0.4072\n",
      "Epoch [3/3], Loss: 0.3606\n",
      "Epoch [3/3], Loss: 0.3515\n",
      "Epoch [3/3], Loss: 0.5509\n",
      "Epoch [3/3], Loss: 0.4659\n",
      "Epoch [3/3], Loss: 0.3694\n",
      "Epoch [3/3], Loss: 0.3891\n",
      "Epoch [3/3], Loss: 0.4207\n",
      "Epoch [3/3], Loss: 0.4223\n",
      "Epoch [3/3], Loss: 0.4923\n",
      "Epoch [3/3], Loss: 0.2302\n",
      "Epoch [3/3], Loss: 0.3831\n",
      "Epoch [3/3], Loss: 0.3030\n",
      "Epoch [3/3], Loss: 0.6428\n",
      "Epoch [3/3], Loss: 0.4402\n",
      "Epoch [3/3], Loss: 0.1635\n",
      "Epoch [3/3], Loss: 0.6052\n",
      "Epoch [3/3], Loss: 0.3649\n",
      "Epoch [3/3], Loss: 0.4980\n",
      "Epoch [3/3], Loss: 0.2579\n",
      "Epoch [3/3], Loss: 0.3553\n",
      "Epoch [3/3], Loss: 0.5093\n",
      "Epoch [3/3], Loss: 0.6170\n",
      "Epoch [3/3], Loss: 0.2959\n",
      "Epoch [3/3], Loss: 0.3324\n",
      "Epoch [3/3], Loss: 0.4231\n",
      "Epoch [3/3], Loss: 0.5480\n",
      "Epoch [3/3], Loss: 0.4515\n",
      "Epoch [3/3], Loss: 0.5552\n",
      "Epoch [3/3], Loss: 0.3094\n",
      "Epoch [3/3], Loss: 0.6500\n",
      "Epoch [3/3], Loss: 0.3525\n",
      "Epoch [3/3], Loss: 0.5544\n",
      "Epoch [3/3], Loss: 0.4138\n",
      "Epoch [3/3], Loss: 0.3109\n",
      "Epoch [3/3], Loss: 0.3725\n",
      "Epoch [3/3], Loss: 0.4121\n",
      "Epoch [3/3], Loss: 0.2722\n",
      "Epoch [3/3], Loss: 0.4251\n",
      "Epoch [3/3], Loss: 0.3375\n",
      "Epoch [3/3], Loss: 0.4104\n",
      "Epoch [3/3], Loss: 0.3270\n",
      "Epoch [3/3], Loss: 0.4434\n",
      "Epoch [3/3], Loss: 0.6449\n",
      "Epoch [3/3], Loss: 0.3954\n",
      "Epoch [3/3], Loss: 0.3998\n",
      "Epoch [3/3], Loss: 0.3028\n",
      "Epoch [3/3], Loss: 0.5447\n",
      "Epoch [3/3], Loss: 0.5176\n",
      "Epoch [3/3], Loss: 0.2399\n",
      "Epoch [3/3], Loss: 0.3858\n",
      "Epoch [3/3], Loss: 0.2957\n",
      "Epoch [3/3], Loss: 0.4686\n",
      "Epoch [3/3], Loss: 0.5736\n",
      "Epoch [3/3], Loss: 0.4142\n",
      "Epoch [3/3], Loss: 0.4871\n",
      "Epoch [3/3], Loss: 0.3863\n",
      "Epoch [3/3], Loss: 0.6861\n",
      "Epoch [3/3], Loss: 0.4653\n",
      "Epoch [3/3], Loss: 0.4094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.4831\n",
      "Epoch [3/3], Loss: 0.2441\n",
      "Epoch [3/3], Loss: 0.3473\n",
      "Epoch [3/3], Loss: 0.2800\n",
      "Epoch [3/3], Loss: 0.3866\n",
      "Epoch [3/3], Loss: 0.5666\n",
      "Epoch [3/3], Loss: 0.7406\n",
      "Epoch [3/3], Loss: 0.3660\n",
      "Epoch [3/3], Loss: 0.3136\n",
      "Epoch [3/3], Loss: 0.5649\n",
      "Epoch [3/3], Loss: 0.2077\n",
      "Epoch [3/3], Loss: 0.4460\n",
      "Epoch [3/3], Loss: 0.3808\n",
      "Epoch [3/3], Loss: 0.4216\n",
      "Epoch [3/3], Loss: 0.5039\n",
      "Epoch [3/3], Loss: 0.2074\n",
      "Epoch [3/3], Loss: 0.6599\n",
      "Epoch [3/3], Loss: 0.5069\n",
      "Epoch [3/3], Loss: 0.8395\n",
      "Epoch [3/3], Loss: 0.6171\n",
      "Epoch [3/3], Loss: 0.3317\n",
      "Epoch [3/3], Loss: 0.3538\n",
      "Epoch [3/3], Loss: 0.4392\n",
      "Epoch [3/3], Loss: 0.3826\n",
      "Epoch [3/3], Loss: 0.4091\n",
      "Epoch [3/3], Loss: 0.4582\n",
      "Epoch [3/3], Loss: 0.3464\n",
      "Epoch [3/3], Loss: 0.4451\n",
      "Epoch [3/3], Loss: 0.4848\n",
      "Epoch [3/3], Loss: 0.4396\n",
      "Epoch [3/3], Loss: 0.3729\n",
      "Epoch [3/3], Loss: 0.5542\n",
      "Epoch [3/3], Loss: 0.5658\n",
      "Epoch [3/3], Loss: 0.5388\n",
      "Epoch [3/3], Loss: 0.3123\n",
      "Epoch [3/3], Loss: 0.6193\n",
      "Epoch [3/3], Loss: 0.3108\n",
      "Epoch [3/3], Loss: 0.5457\n",
      "Epoch [3/3], Loss: 0.5812\n",
      "Epoch [3/3], Loss: 0.4245\n",
      "Epoch [3/3], Loss: 0.3190\n",
      "Epoch [3/3], Loss: 0.3631\n",
      "Epoch [3/3], Loss: 0.5089\n",
      "Epoch [3/3], Loss: 0.4240\n",
      "Epoch [3/3], Loss: 0.4376\n",
      "Epoch [3/3], Loss: 0.4545\n",
      "Epoch [3/3], Loss: 0.3461\n",
      "Epoch [3/3], Loss: 0.3871\n",
      "Epoch [3/3], Loss: 0.3040\n",
      "Epoch [3/3], Loss: 0.3974\n",
      "Epoch [3/3], Loss: 0.5621\n",
      "Epoch [3/3], Loss: 0.5259\n",
      "Epoch [3/3], Loss: 0.6224\n",
      "Epoch [3/3], Loss: 0.4775\n",
      "Epoch [3/3], Loss: 0.4818\n",
      "Epoch [3/3], Loss: 0.5009\n",
      "Epoch [3/3], Loss: 0.4673\n",
      "Epoch [3/3], Loss: 0.5229\n",
      "Epoch [3/3], Loss: 0.4316\n",
      "Epoch [3/3], Loss: 0.3675\n",
      "Epoch [3/3], Loss: 0.5101\n",
      "Epoch [3/3], Loss: 0.4620\n",
      "Epoch [3/3], Loss: 0.3461\n",
      "Epoch [3/3], Loss: 0.6565\n",
      "Epoch [3/3], Loss: 0.7327\n",
      "Epoch [3/3], Loss: 0.3627\n",
      "Epoch [3/3], Loss: 0.2479\n",
      "Epoch [3/3], Loss: 0.6582\n",
      "Epoch [3/3], Loss: 0.3802\n",
      "Epoch [3/3], Loss: 0.3169\n",
      "Epoch [3/3], Loss: 0.3592\n",
      "Epoch [3/3], Loss: 0.6725\n",
      "Epoch [3/3], Loss: 0.4433\n",
      "Epoch [3/3], Loss: 0.4057\n",
      "Epoch [3/3], Loss: 0.5941\n",
      "Epoch [3/3], Loss: 0.4550\n",
      "Epoch [3/3], Loss: 0.6019\n",
      "Epoch [3/3], Loss: 0.4208\n",
      "Epoch [3/3], Loss: 0.3434\n",
      "Epoch [3/3], Loss: 0.4612\n",
      "Epoch [3/3], Loss: 0.2882\n",
      "Epoch [3/3], Loss: 0.4482\n",
      "Epoch [3/3], Loss: 0.6448\n",
      "Epoch [3/3], Loss: 0.2921\n",
      "Epoch [3/3], Loss: 0.5020\n",
      "Epoch [3/3], Loss: 0.5051\n",
      "Epoch [3/3], Loss: 0.5838\n",
      "Epoch [3/3], Loss: 0.3006\n",
      "Epoch [3/3], Loss: 0.4258\n",
      "Epoch [3/3], Loss: 0.3000\n",
      "Epoch [3/3], Loss: 0.7163\n",
      "Epoch [3/3], Loss: 0.3768\n",
      "Epoch [3/3], Loss: 0.5640\n",
      "Epoch [3/3], Loss: 0.3114\n",
      "Epoch [3/3], Loss: 0.5034\n",
      "Epoch [3/3], Loss: 0.5619\n",
      "Epoch [3/3], Loss: 0.5670\n",
      "Epoch [3/3], Loss: 0.4351\n",
      "Epoch [3/3], Loss: 0.2499\n",
      "Epoch [3/3], Loss: 0.5433\n",
      "Epoch [3/3], Loss: 0.5454\n",
      "Epoch [3/3], Loss: 0.2358\n",
      "Epoch [3/3], Loss: 0.5489\n",
      "Epoch [3/3], Loss: 0.2620\n",
      "Epoch [3/3], Loss: 0.2888\n",
      "Epoch [3/3], Loss: 0.2660\n",
      "Epoch [3/3], Loss: 0.3709\n",
      "Epoch [3/3], Loss: 0.4223\n",
      "Epoch [3/3], Loss: 0.3745\n",
      "Epoch [3/3], Loss: 0.6489\n",
      "Epoch [3/3], Loss: 0.3165\n",
      "Epoch [3/3], Loss: 0.3225\n",
      "Epoch [3/3], Loss: 0.3354\n",
      "Epoch [3/3], Loss: 0.3552\n",
      "Epoch [3/3], Loss: 0.3587\n",
      "Epoch [3/3], Loss: 0.2854\n",
      "Epoch [3/3], Loss: 0.3733\n",
      "Epoch [3/3], Loss: 0.2600\n",
      "Epoch [3/3], Loss: 0.6051\n",
      "Epoch [3/3], Loss: 0.2371\n",
      "Epoch [3/3], Loss: 0.3311\n",
      "Epoch [3/3], Loss: 0.4323\n",
      "Epoch [3/3], Loss: 0.6102\n",
      "Epoch [3/3], Loss: 0.3051\n",
      "Epoch [3/3], Loss: 0.4566\n",
      "Epoch [3/3], Loss: 0.4518\n",
      "Epoch [3/3], Loss: 0.4167\n",
      "Epoch [3/3], Loss: 0.2353\n",
      "Epoch [3/3], Loss: 0.6247\n",
      "Epoch [3/3], Loss: 0.3502\n",
      "Epoch [3/3], Loss: 0.3704\n",
      "Epoch [3/3], Loss: 0.2450\n",
      "Epoch [3/3], Loss: 0.3142\n",
      "Epoch [3/3], Loss: 0.4119\n",
      "Epoch [3/3], Loss: 0.3275\n",
      "Epoch [3/3], Loss: 0.4350\n",
      "Epoch [3/3], Loss: 0.3121\n",
      "Epoch [3/3], Loss: 0.5107\n",
      "Epoch [3/3], Loss: 0.5192\n",
      "Epoch [3/3], Loss: 0.3446\n",
      "Epoch [3/3], Loss: 0.3386\n",
      "Epoch [3/3], Loss: 0.2326\n",
      "Epoch [3/3], Loss: 0.3314\n",
      "Epoch [3/3], Loss: 0.2967\n",
      "Epoch [3/3], Loss: 0.5081\n",
      "Epoch [3/3], Loss: 0.5771\n",
      "Epoch [3/3], Loss: 0.4153\n",
      "Epoch [3/3], Loss: 0.4306\n",
      "Epoch [3/3], Loss: 0.3232\n",
      "Epoch [3/3], Loss: 0.4857\n",
      "Epoch [3/3], Loss: 0.4838\n",
      "Epoch [3/3], Loss: 0.5845\n",
      "Epoch [3/3], Loss: 0.3337\n",
      "Epoch [3/3], Loss: 0.4596\n",
      "Epoch [3/3], Loss: 0.4231\n",
      "Epoch [3/3], Loss: 0.4136\n",
      "Epoch [3/3], Loss: 0.2930\n",
      "Epoch [3/3], Loss: 0.3039\n",
      "Epoch [3/3], Loss: 0.6564\n",
      "Epoch [3/3], Loss: 0.2661\n",
      "Epoch [3/3], Loss: 0.3281\n",
      "Epoch [3/3], Loss: 0.3790\n",
      "Epoch [3/3], Loss: 0.3791\n",
      "Epoch [3/3], Loss: 0.2757\n",
      "Epoch [3/3], Loss: 0.5165\n",
      "Epoch [3/3], Loss: 0.3925\n",
      "Epoch [3/3], Loss: 0.5696\n",
      "Epoch [3/3], Loss: 0.3144\n",
      "Epoch [3/3], Loss: 0.5029\n",
      "Epoch [3/3], Loss: 0.2692\n",
      "Epoch [3/3], Loss: 0.4095\n",
      "Epoch [3/3], Loss: 0.4744\n",
      "Epoch [3/3], Loss: 0.5603\n",
      "Epoch [3/3], Loss: 0.2969\n",
      "Epoch [3/3], Loss: 0.2303\n",
      "Epoch [3/3], Loss: 0.3591\n",
      "Epoch [3/3], Loss: 0.2809\n",
      "Epoch [3/3], Loss: 0.3684\n",
      "Epoch [3/3], Loss: 0.2963\n",
      "Epoch [3/3], Loss: 0.5437\n",
      "Epoch [3/3], Loss: 0.3911\n",
      "Epoch [3/3], Loss: 0.4172\n",
      "Epoch [3/3], Loss: 0.3791\n",
      "Epoch [3/3], Loss: 0.3932\n",
      "Epoch [3/3], Loss: 0.3327\n",
      "Epoch [3/3], Loss: 0.4125\n",
      "Epoch [3/3], Loss: 0.5543\n",
      "Epoch [3/3], Loss: 0.2351\n",
      "Epoch [3/3], Loss: 0.5421\n",
      "Epoch [3/3], Loss: 0.5022\n",
      "Epoch [3/3], Loss: 0.2133\n",
      "Epoch [3/3], Loss: 0.2602\n",
      "Epoch [3/3], Loss: 0.4502\n",
      "Epoch [3/3], Loss: 0.4322\n",
      "Epoch [3/3], Loss: 0.3393\n",
      "Epoch [3/3], Loss: 0.4093\n",
      "Epoch [3/3], Loss: 0.5641\n",
      "Epoch [3/3], Loss: 0.3515\n",
      "Epoch [3/3], Loss: 0.3476\n",
      "Epoch [3/3], Loss: 0.3900\n",
      "Epoch [3/3], Loss: 0.5428\n",
      "Epoch [3/3], Loss: 0.4966\n",
      "Epoch [3/3], Loss: 0.4629\n",
      "Epoch [3/3], Loss: 0.1578\n",
      "Epoch [3/3], Loss: 0.3375\n",
      "Epoch [3/3], Loss: 0.2962\n",
      "Epoch [3/3], Loss: 0.1789\n",
      "Epoch [3/3], Loss: 0.3297\n",
      "Epoch [3/3], Loss: 0.3894\n",
      "Epoch [3/3], Loss: 0.3605\n",
      "Epoch [3/3], Loss: 0.3852\n",
      "Epoch [3/3], Loss: 0.3570\n",
      "Epoch [3/3], Loss: 0.3904\n",
      "Epoch [3/3], Loss: 0.2675\n",
      "Epoch [3/3], Loss: 0.5034\n",
      "Epoch [3/3], Loss: 0.3295\n",
      "Epoch [3/3], Loss: 0.4446\n",
      "Epoch [3/3], Loss: 0.4735\n",
      "Epoch [3/3], Loss: 0.3934\n",
      "Epoch [3/3], Loss: 0.3065\n",
      "Epoch [3/3], Loss: 0.2629\n",
      "Epoch [3/3], Loss: 0.4664\n",
      "Epoch [3/3], Loss: 0.1638\n",
      "Epoch [3/3], Loss: 0.3107\n",
      "Epoch [3/3], Loss: 0.4024\n",
      "Epoch [3/3], Loss: 0.3934\n",
      "Epoch [3/3], Loss: 0.5317\n",
      "Epoch [3/3], Loss: 0.4252\n",
      "Epoch [3/3], Loss: 0.4379\n",
      "Epoch [3/3], Loss: 0.4447\n",
      "Epoch [3/3], Loss: 0.6477\n",
      "Epoch [3/3], Loss: 0.5550\n",
      "Epoch [3/3], Loss: 0.2999\n",
      "Epoch [3/3], Loss: 0.3719\n",
      "Epoch [3/3], Loss: 0.3866\n",
      "Epoch [3/3], Loss: 0.3242\n",
      "Epoch [3/3], Loss: 0.5996\n",
      "Epoch [3/3], Loss: 0.5316\n",
      "Epoch [3/3], Loss: 0.2596\n",
      "Epoch [3/3], Loss: 0.4110\n",
      "Epoch [3/3], Loss: 0.4415\n",
      "Epoch [3/3], Loss: 0.2555\n",
      "Epoch [3/3], Loss: 0.3502\n",
      "Epoch [3/3], Loss: 0.1507\n",
      "Epoch [3/3], Loss: 0.1796\n",
      "Epoch [3/3], Loss: 0.3552\n",
      "Epoch [3/3], Loss: 0.5035\n",
      "Epoch [3/3], Loss: 0.4796\n",
      "Epoch [3/3], Loss: 0.5069\n",
      "Epoch [3/3], Loss: 0.2203\n",
      "Epoch [3/3], Loss: 0.3441\n",
      "Epoch [3/3], Loss: 0.3965\n",
      "Epoch [3/3], Loss: 0.2540\n",
      "Epoch [3/3], Loss: 0.2838\n",
      "Epoch [3/3], Loss: 0.2538\n",
      "Epoch [3/3], Loss: 0.1402\n",
      "Epoch [3/3], Loss: 0.2307\n",
      "Epoch [3/3], Loss: 0.4748\n",
      "Epoch [3/3], Loss: 0.3429\n",
      "Epoch [3/3], Loss: 0.2848\n",
      "Epoch [3/3], Loss: 0.2779\n",
      "Epoch [3/3], Loss: 0.2738\n",
      "Epoch [3/3], Loss: 0.4523\n",
      "Epoch [3/3], Loss: 0.2893\n",
      "Epoch [3/3], Loss: 0.4058\n",
      "Epoch [3/3], Loss: 0.3947\n",
      "Epoch [3/3], Loss: 0.5606\n",
      "Epoch [3/3], Loss: 0.3848\n",
      "Epoch [3/3], Loss: 0.6048\n",
      "Epoch [3/3], Loss: 0.2784\n",
      "Epoch [3/3], Loss: 0.5465\n",
      "Epoch [3/3], Loss: 0.3905\n",
      "Epoch [3/3], Loss: 0.5121\n",
      "Epoch [3/3], Loss: 0.2884\n",
      "Epoch [3/3], Loss: 0.3695\n",
      "Epoch [3/3], Loss: 0.4947\n",
      "Epoch [3/3], Loss: 0.2798\n",
      "Epoch [3/3], Loss: 0.4249\n",
      "Epoch [3/3], Loss: 0.4877\n",
      "Epoch [3/3], Loss: 0.3538\n",
      "Epoch [3/3], Loss: 0.4100\n",
      "Epoch [3/3], Loss: 0.5511\n",
      "Epoch [3/3], Loss: 0.2572\n",
      "Epoch [3/3], Loss: 0.4886\n",
      "Epoch [3/3], Loss: 0.2189\n",
      "Epoch [3/3], Loss: 0.4180\n",
      "Epoch [3/3], Loss: 0.4745\n",
      "Epoch [3/3], Loss: 0.5711\n",
      "Epoch [3/3], Loss: 0.2849\n",
      "Epoch [3/3], Loss: 0.2360\n",
      "Epoch [3/3], Loss: 0.3573\n",
      "Epoch [3/3], Loss: 0.3708\n",
      "Epoch [3/3], Loss: 0.4382\n",
      "Epoch [3/3], Loss: 0.5435\n",
      "Epoch [3/3], Loss: 0.5777\n",
      "Epoch [3/3], Loss: 0.4642\n",
      "Epoch [3/3], Loss: 0.4047\n",
      "Epoch [3/3], Loss: 0.4119\n",
      "Epoch [3/3], Loss: 0.5386\n",
      "Epoch [3/3], Loss: 0.2714\n",
      "Epoch [3/3], Loss: 0.2827\n",
      "Epoch [3/3], Loss: 0.2137\n",
      "Epoch [3/3], Loss: 0.4035\n",
      "Epoch [3/3], Loss: 0.4822\n",
      "Epoch [3/3], Loss: 0.5191\n",
      "Epoch [3/3], Loss: 0.4448\n",
      "Epoch [3/3], Loss: 0.3287\n",
      "Epoch [3/3], Loss: 0.1856\n",
      "Epoch [3/3], Loss: 0.3456\n",
      "Epoch [3/3], Loss: 0.4957\n",
      "Epoch [3/3], Loss: 0.3154\n",
      "Epoch [3/3], Loss: 0.1953\n",
      "Epoch [3/3], Loss: 0.3962\n",
      "Epoch [3/3], Loss: 0.5861\n",
      "Epoch [3/3], Loss: 0.3331\n",
      "Epoch [3/3], Loss: 0.4110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.2800\n",
      "Epoch [3/3], Loss: 0.4288\n",
      "Epoch [3/3], Loss: 0.5011\n",
      "Epoch [3/3], Loss: 0.4378\n",
      "Epoch [3/3], Loss: 0.3617\n",
      "Epoch [3/3], Loss: 0.4988\n",
      "Epoch [3/3], Loss: 0.5420\n",
      "Epoch [3/3], Loss: 0.4223\n",
      "Epoch [3/3], Loss: 0.3322\n",
      "Epoch [3/3], Loss: 0.3306\n",
      "Epoch [3/3], Loss: 0.4033\n",
      "Epoch [3/3], Loss: 0.3711\n",
      "Epoch [3/3], Loss: 0.3711\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(CNN,self).__init__()\n",
    "        # input channels is 3 because of RGB channels\n",
    "        #((w-f+2P)/s) + 1\n",
    "#         self.conv_l1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3)\n",
    "#         self.conv_l2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
    "        self.conv_l1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3)\n",
    "        self.conv_l2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "#         self.conv_l3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "#         self.conv_l4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "        self.conv_l3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "        self.conv_l4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_l5 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "        self.conv_l6 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "#         self.conv_l5 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "#         self.conv_l6 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "#         self.max_pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(50176,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "#         print(x.size())\n",
    "        out = self.conv_l1(x)\n",
    "#         print(out.size())\n",
    "        out = self.conv_l2(out)\n",
    "#         print(out.size())\n",
    "        out = self.max_pool1(out)\n",
    "#         print(out.size())\n",
    "        out = self.conv_l3(out)\n",
    "#         print(out.size())\n",
    "        out = self.conv_l4(out)\n",
    "#         print(out.size())\n",
    "        out = self.max_pool2(out)\n",
    "    \n",
    "        out = self.conv_l5(out)\n",
    "#         print(out.size())\n",
    "        out = self.conv_l6(out)\n",
    "#         print(out.size())\n",
    "        out = self.max_pool2(out)\n",
    "#         print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "#         print(out.size())\n",
    "        out = self.fc1(out)\n",
    "#         print(out.size())\n",
    "        out = self.relu1(out)\n",
    "#         print(out.size())\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# layers = [module for module in model.modules()][1:]\n",
    "# summary(CNN(12),(32, 3, 256, 256))\n",
    "# layers\n",
    "\n",
    "model = CNN(num_classes)\n",
    "print(model)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "# total_step = len(train_loader)\n",
    "total_step = len(train_loader_balanced)\n",
    "\n",
    "best_score = None\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\t#Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader_balanced):\n",
    "#     for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "        \n",
    "    if best_score is None:\n",
    "        best_score = loss\n",
    "    else:\n",
    "            # Check if val_loss improves or not.\n",
    "        if loss < best_score:\n",
    "                # val_loss improves, we update the latest best_score, \n",
    "                # and save the current model\n",
    "            best_score = loss\n",
    "            torch.save(model.state_dict(), CNN_PATH)\n",
    "        else:\n",
    "                # val_loss does not improve, we increase the counter, \n",
    "                # stop training if it exceeds the amount of patience\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "    if epoch == num_epochs:\n",
    "        torch.save(model.state_dict(), CNN_PATH)\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0465b3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_l1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv_l2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_l3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv_l4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_l5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv_l6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=50176, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c1492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 40000 train images: 94.08 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader_balanced:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c4a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 56.21 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(CNN(12),(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.functional.get_image_size(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.str_label[1500])\n",
    "Image.open(test_df.img_path[1500])\n",
    "print(train_df.str_label[1000],train_df.img_path[1000])\n",
    "Image.open(train_df.img_path[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5e9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_df.str_label[1000],train_df.img_path[1000])\n",
    "Image.open(train_df.img_path[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d569818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,0.5,0.5),(0.5, 0.5, 0.5))]\n",
    "#     )\n",
    "\n",
    "# test_data = datasets.ImageFolder('/workspace/resnet/data/raw/test/', transform=transform)\n",
    "# test_data_loader  = data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4) \n",
    "\n",
    "# train_data = datasets.ImageFolder('/workspace/resnet/data/raw/train/', transform=transform)\n",
    "# train_data_loader  = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4) \n",
    "\n",
    "# train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
