{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7fc152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\n",
    "import os\n",
    "import ast\n",
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import helper\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "num_classes = 12\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "patience = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "ROOT_DIR = \"/workspace/resnet/\"\n",
    "ROOT_DATA_DIR = \"/workspace/resnet/data/raw\"\n",
    "ARCHIVE_DIR = os.path.join(ROOT_DATA_DIR, \"archive.zip\")\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR)#, \"labelme-12-50k\")\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TRAIN_ANNOT_PATH = os.path.join(TRAIN_DIR, \"annotation.txt\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "TEST_ANNOT_PATH = os.path.join(TEST_DIR, \"annotation.txt\")\n",
    "CLASSES_TXT_PATH = os.path.join(DATA_DIR, \"classes.txt\")\n",
    "INTERIM_DATA_DIR = \"/workspace/resnet/data/interim/\"\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "CNN_PATH = os.path.join(MODEL_DIR, \"2.1_resnet-balanced\")\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile(ARCHIVE_DIR, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(ROOT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a023b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83419f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_balanced = pd.read_csv(os.path.join(INTERIM_DATA_DIR,\"balanced-train-40000.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(INTERIM_DATA_DIR,\"test-10000.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e6e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5, 0.5, 0.5))]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3617ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,annot_df,transform = None):\n",
    "        self.annotations = annot_df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img = Image.open(self.annotations.img_path[index])\n",
    "        y_label = torch.tensor(int(self.annotations.int_label[index]))\n",
    "        if self.transform:\n",
    "            image = transform(img)\n",
    "        else:\n",
    "            image = img\n",
    "        return (image,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3233bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f6c8e3e37c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = MyDataset(train_df,transform = transform)\n",
    "test_data = MyDataset(test_df,transform = transform)\n",
    "train_data_balanced = MyDataset(train_df_balanced,transform = transform)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
    "train_loader_balanced = DataLoader(dataset = train_data_balanced, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f66bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3438\n",
       "9     3422\n",
       "7     3392\n",
       "6     3325\n",
       "11    3317\n",
       "10    3312\n",
       "8     3305\n",
       "1     3303\n",
       "2     3302\n",
       "4     3297\n",
       "5     3295\n",
       "3     3292\n",
       "Name: int_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_balanced.int_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "330e303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create blocks then build resnet architecture\n",
    "\n",
    "# identity downsample is going to be a conv layer which might be required if input size has changed or if the number of channels have changed.\n",
    "# adapt identity to be added later once a few conv layers have gone through\n",
    "class block(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels, identity_downsample = None, stride = 1):\n",
    "        super(block,self).__init__()\n",
    "        self.expansion = 4 # the number of channels after a block is 4 times what it was before it entered\n",
    "        self.conv_res1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1 , stride = 1, padding = 0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv_res2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3 , stride = stride, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv_res3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size = 1 , stride = 1, padding = 0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion) #expand by 4\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        # go through identity layer in each mentioned layer above\n",
    "        x = self.conv_res1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_res2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_res3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8bc1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv_l1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): block(\n",
      "      (conv_res1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv_res1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv_res1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): block(\n",
      "      (conv_res1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv_res1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv_res1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): block(\n",
      "      (conv_res1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): block(\n",
      "      (conv_res1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): block(\n",
      "      (conv_res1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): block(\n",
      "      (conv_res1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_res3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1024, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block, layers, image_channels=3, num_classes=12):\n",
    "        #block is the block from the previous cell\n",
    "        #layers is a list, tells us number of times to use the previous block [3,4,6]\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv_l1 = nn.Conv2d(in_channels = image_channels, out_channels = 64, kernel_size = 7,stride = 2, padding = 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        # ResNet Layers\n",
    "        self.layer1 = self._make_layer(block,layers[0], out_channels = 64, stride = 1)\n",
    "        self.layer2 = self._make_layer(block,layers[1], out_channels = 128, stride = 2)\n",
    "        self.layer3 = self._make_layer(block,layers[2], out_channels = 256, stride = 2)\n",
    "        self.layer3 = self._make_layer(block,layers[3], out_channels = 256, stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256*4, num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv_l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self,block,num_residual_blocks,out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = [] # empty added as we proceed\n",
    "        \n",
    "        # below is when we are going to do an identity downsample\n",
    "        # if size/number of channels changes. This is the only way for it to be added \n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels,out_channels*4,kernel_size = 1,stride = stride),\n",
    "                                               nn.BatchNorm2d(out_channels*4))\n",
    "        # change the number of channels\n",
    "        # after we append to the list we change the number of channels\n",
    "        layers.append(block(self.in_channels,out_channels,identity_downsample,stride))\n",
    "        # update in_channels\n",
    "        self.in_channels = out_channels*4\n",
    "        \n",
    "        for i in range(num_residual_blocks -1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "\n",
    "# model = ResNet(block,[3,4,6,3], 3, 12)\n",
    "model = ResNet(block,[3,4,6,3], 3, 12)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "# total_step = len(train_loader)\n",
    "total_step = len(train_loader_balanced)\n",
    "\n",
    "best_score = None\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\t#Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader_balanced):\n",
    "#     for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "        \n",
    "    if best_score is None:\n",
    "        best_score = loss\n",
    "    else:\n",
    "            # Check if val_loss improves or not.\n",
    "        if loss < best_score:\n",
    "                # val_loss improves, we update the latest best_score, \n",
    "                # and save the current model\n",
    "            best_score = loss\n",
    "            torch.save(model.state_dict(), CNN_PATH)\n",
    "        else:\n",
    "                # val_loss does not improve, we increase the counter, \n",
    "                # stop training if it exceeds the amount of patience\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "    if epoch == num_epochs:\n",
    "        torch.save(model.state_dict(), CNN_PATH)\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader_balanced:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        prin\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(total, 100 * correct / total))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(CNN(12),(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.functional.get_image_size(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.str_label[1500])\n",
    "Image.open(test_df.img_path[1500])\n",
    "print(train_df.str_label[1000],train_df.img_path[1000])\n",
    "Image.open(train_df.img_path[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5e9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_df.str_label[1000],train_df.img_path[1000])\n",
    "Image.open(train_df.img_path[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d569818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,0.5,0.5),(0.5, 0.5, 0.5))]\n",
    "#     )\n",
    "\n",
    "# test_data = datasets.ImageFolder('/workspace/resnet/data/raw/test/', transform=transform)\n",
    "# test_data_loader  = data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4) \n",
    "\n",
    "# train_data = datasets.ImageFolder('/workspace/resnet/data/raw/train/', transform=transform)\n",
    "# train_data_loader  = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4) \n",
    "\n",
    "# train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
